[
  {
    "objectID": "digital-garden.html",
    "href": "digital-garden.html",
    "title": "Guillaume Gilles",
    "section": "",
    "text": "print(‘Hello World!’)\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFundamental Papers in Artificial Intelligence\n\n\n\nsprout\n\n\n\nHype around foundation models, like GPT and Llama, comes with a deluge of papers. Let’s focus on the fundamental ones that cross time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVoronoi Stippling\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWandering Around in Digital Gardens\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Jungle of Markdown Dialect\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "digital-garden/wandering-around-digital-gardens/index.html",
    "href": "digital-garden/wandering-around-digital-gardens/index.html",
    "title": "Wandering Around in Digital Gardens",
    "section": "",
    "text": "categories: 1. seed: first ideas through randomly 2. sprout: 3. sapling: 4. evergreen: finished note, could be compared to a blog post.\n\nReferences"
  },
  {
    "objectID": "digital-garden/voronoi-stippling/index.html",
    "href": "digital-garden/voronoi-stippling/index.html",
    "title": "Voronoi Stippling",
    "section": "",
    "text": "https://observablehq.com/(mbostock/voronoi-stippling?)\n\nwhat is vornoi?\nwhat is stippling?\n\nThe fascinating world of Voronoi diagrams\nhttps://www.youtube.com/watch?v=Bxdt6T_1qgc&t=218s\n\nReferences"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Hi! I appreciate you dropping by.",
    "section": "",
    "text": "Website\n  \n  \n    \n     Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Kaggle\n  \n\n  \n  \nI’m Guillaume Gilles, a data analyst at Banque de France and an adjunct professor at INSEEC and ESSCA. I am passionate about machine learning! I strive to understand how machine learning algorithms are applied to solve real-world problems and I enjoy every part of a machine learning lifecycle: data preparation, modelization, and reporting to stakeholders.\nI studied economics, finance, and computer science, but mostly, I’m a lifelong learner! I worked as a financial analyst before moving into data science in 2020.\nWhen I am not working, I am trying my best to be a husband, father of one son, and a cat owner. I love taking care of my cat, Othello a.k.a. skekCoon based on Skeksis and his breed, Mainecoon.\n\n\n\nPython = ['pandas', 'scikit-learn', 'xgboost']\n\n\nR &lt;- c('Tidyverse', 'Tidymodels')\nPassionate and results-driven economist and statistician with a focus on leveraging machine learning and deep learning to address real-world challenges. Proficient in every aspect of the machine learning lifecycle, from data preparation to modelization and reporting. Experienced in economic analysis, financial strategy, and investment, with a keen interest in exploring the intersection of finance and technology. Committed to continuous learning and contributing to meaningful projects that make a positive impact."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Hi! I appreciate you dropping by.",
    "section": "Experience",
    "text": "Experience\n\nEconomist & Statistician\nBank of France | Dec 2020 – present\n\nI specialize in analyzing data to uncover underlying trends, forecast economic indicators, and provide valuable insights for informed decision-making.\nI thrive on utilizing cutting-edge statistical methods and econometric techniques to derive meaningful conclusions and drive positive outcomes.\nProficient in statistical software such as R, Python, and Excel, I am adept at handling large datasets and employing both statistical and deep learning techniques to solve real-world problems.\n\n\n\nAdjunct Professor\nESSCA | Jan 2024 – present\n\nDynamic and dedicated lecturer with a passion for fostering academic excellence and nurturing the next generation of business leaders.\nI excel in creating engaging and impactful learning experiences in both descriptive and inferential statistics.\n\n\n\nAdjunct Professor\nINSEEC MSc & MBA | March 2019 – present\n\nLeveraging a strong background in business theory and practical industry experience, I am delivering courses in finance analysis, and strategy.\nCommitted to student success, I employ innovative teaching methods, develop comprehensive course materials, and provide mentorship to cultivate critical thinking and professional skills.\n\n\n\nSenior Financial Analyst\nBank of France | Feb 2011 – Dec 2020\n\nProficient and detail-oriented financial analyst with 8 years of experience in analyzing financial data, identifying trends, and providing actionable insights to support strategic decision-making.\nProficient in conducting risk assessments, stress testing, and scenario analysis to evaluate potential impacts on financial portfolios.\nExpertise in analyzing credit risk, market risk, and operational risk, with a strong understanding of regulatory requirements and compliance standards.\nSkilled in financial modeling, forecasting, and budgeting, with a strong understanding of accounting principles and financial regulations.\nProven ability to communicate complex financial information effectively to stakeholders at all levels.\nCommitted to continuous learning and professional development to stay abreast of industry trends and best practices in financial analysis."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Hi! I appreciate you dropping by.",
    "section": "Education",
    "text": "Education\n\nData Scientist Certification\nENSAE | Nov 2022 – May 2023\nI have completed a comprehensive 6 months data science certification program that provided me with in-depth knowledge and practical skills in the field. This certification covered a wide range of topics essential to data science, including data analysis, machine learning, statistical modeling, and data visualization. Throughout the program, I gained hands-on experience with various tools and technologies commonly used in the industry, such as Python, R, and SQL.\nAdditionally, I participated in projects and case studies that allowed me to apply theoretical concepts to real-world scenarios, honing my problem-solving abilities and enhancing my understanding of best practices in data science. This certification has equipped me with the expertise and confidence to tackle complex data challenges and make meaningful contributions in the rapidly evolving field of data science.\n\n\nComputer Science Applied to Business Management Master’s degree\nUniversity of Bordeaux, France | Jan 2020 - Dec 2022\nI hold a Master’s degree in Computer Science, which has provided me with a comprehensive understanding of advanced concepts and techniques in the field. Throughout my studies, I delved into a wide range of topics including algorithms, artificial intelligence, database systems, software engineering, and cybersecurity.\nI engaged in hands-on projects, research endeavors, and collaborative activities that enabled me to deepen my technical skills and expand my problem-solving capabilities. Additionally, I gained proficiency in various programming languages, such as Java, C++, and Python, as well as familiarity with cutting-edge technologies and tools. My Master’s program equipped me with the knowledge, expertise, and adaptability necessary to thrive in today’s fast-paced and ever-evolving landscape of computer science.\n\n\nFinance, Corporate, and Banking Investment Master’s degree\nBusiness School University of Bordeaux, France | Sept 2018 - June 2019\nI graduated valedictorian of a prestigious Corporate and Investment Banking Master’s program, where I acquired specialized knowledge and expertise in the intricacies of financial markets, investment strategies, and corporate finance. Throughout my studies, I gained a comprehensive understanding of financial instruments, including securities, derivatives, and structured products, as well as their role in capital markets. I honed my analytical skills through rigorous coursework in financial modeling, valuation techniques, and risk management methodologies.\nThrough practical case studies, I developed a deep appreciation for the complexities of the banking industry and cultivated the critical thinking and problem-solving abilities necessary to navigate its challenges.\n\n\nFinancial Analysis Certification\nESSEC Business School | 2015 – 2016\nAn intensive financial analysis certification program from ESSEC Business School partnered with Banque of France that provided in-depth practical skills in financial modeling, ratio analysis, and cash flow forecasting, using industry-standard tools such as Excel and financial analysis software.\n\n\nManagement Science Licence’s degree\nBusiness School University of Amiens, France | Sept 2008 - June 2009"
  },
  {
    "objectID": "about.html#languages",
    "href": "about.html#languages",
    "title": "Hi! I appreciate you dropping by.",
    "section": "Languages",
    "text": "Languages\n\nFrench: Native\nEnglish: Fluent (C1)"
  },
  {
    "objectID": "about.html#hobbies",
    "href": "about.html#hobbies",
    "title": "Hi! I appreciate you dropping by.",
    "section": "Hobbies",
    "text": "Hobbies\n\nReading novels and essays\nScience fiction: Dune, Star Wars, Blade Runner, etc.\nSports: jogging, karate - 2nd DAN"
  },
  {
    "objectID": "ibs/ch02-data-sampling-variation.html",
    "href": "ibs/ch02-data-sampling-variation.html",
    "title": "Data, Sampling, and Variation in Data and Sampling Data",
    "section": "",
    "text": "Data may come from a population or from a sample. Lowercase letters like \\(x\\) or \\(y\\) generally are used to represent data values. Most data can be put into the following categories:\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative (categorical) data. Qualitative (categorical) data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative (categorical) data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like \\(2.4\\), \\(7.5\\), or \\(11.0\\), would be quantitative continuous data.\nThe following graph is the same as the previous graph but the “Other/Unknown” percent (9.6%) has been included. The “Other/Unknown” category is large compared to some of the other categories (Native American, 0.6%, Pacific Islander 1.0%). This is important to know when we think about what the data are telling us.\nThis particular bar graph in Figure 1.8 can be difficult to understand visually. The graph in Figure 1.9 is a Pareto chart. The Pareto chart has the bars sorted from largest to smallest and is easier to read and interpret.\nPie Charts: No Missing Data The following pie charts have the “Other/Unknown” category included (since the percentages must add to 100%). The chart in Figure 1.10(b) is organized by the size of each wedge, which makes it a more visually informative graph than the unsorted, alphabetical graph in Figure 1.10(a).",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Data, Sampling, and Variation in Data and Sampling Data"
    ]
  },
  {
    "objectID": "ibs/ch02-data-sampling-variation.html#qualitative-data-discussion",
    "href": "ibs/ch02-data-sampling-variation.html#qualitative-data-discussion",
    "title": "Data, Sampling, and Variation in Data and Sampling Data",
    "section": "Qualitative Data Discussion",
    "text": "Qualitative Data Discussion\nBelow are tables comparing the number of part-time and full-time students at De Anza College and Foothill College enrolled for the most recent spring quarter. The tables display counts (frequencies) and percentages or proportions (relative frequencies). The percent columns make comparing the same categories in the colleges easier. Displaying percentages along with the numbers is often helpful, but it is particularly important when comparing sets of data that do not have the same totals, such as the total enrollments for both colleges in this example. Notice how much larger the percentage for part-time students at Foothill College is compared to De Anza College.\nDe Anza College | Foothill College |\n| Number | Percent | | Number | Percent|\n|-|——–|———|-|——–|——–| |Full-time | 9,200 | 40.9% | Full-time | 4,059 | 28.6% | | Part-time| 13,296| 59.1%| Part-time | 10,124 | 71.4% | |Total| 22,496 | 100% | Total | 14,183 | 100% |\n\nimport pandas as pd\ndata = {\"product_name\":[\"Keyboard\",\"Mouse\", \"Monitor\", \"CPU\",\"CPU\", \"Speakers\", pd.NaT],\n        \"Unit_Price\":[500,200, 5000.235, 10000.550, 10000.550, 250.50,None],\n        \"No_Of_Units\":[5,5, 10, 20, 20, 8,pd.NaT],\n        \"Available_Quantity\":[5,6,10,\"Not Available\",\"Not Available\", pd.NaT, pd.NaT],\n        \"Available_Since_Date\":['11/5/2021', '4/23/2021', '08/21/2021', '09/18/2021', '09/18/2021', '01/05/2021', pd.NaT]\n       }\ndf = pd.DataFrame(data)\ndf = df.astype({\"Unit_Price\": float})\ndf\n\n\n\n\n\n\n\n\nproduct_name\nUnit_Price\nNo_Of_Units\nAvailable_Quantity\nAvailable_Since_Date\n\n\n\n\n0\nKeyboard\n500.000\n5\n5\n11/5/2021\n\n\n1\nMouse\n200.000\n5\n6\n4/23/2021\n\n\n2\nMonitor\n5000.235\n10\n10\n08/21/2021\n\n\n3\nCPU\n10000.550\n20\nNot Available\n09/18/2021\n\n\n4\nCPU\n10000.550\n20\nNot Available\n09/18/2021\n\n\n5\nSpeakers\n250.500\n8\nNaT\n01/05/2021\n\n\n6\nNaT\nNaN\nNaT\nNaT\nNaT\n\n\n\n\n\n\n\nTables are a good way of organizing and displaying data. But graphs can be even more helpful in understanding the data. There are no strict rules concerning which graphs to use. Two graphs that are used to display qualitative (categorical) data are pie charts and bar graphs.\n\nIn a pie chart, categories of data are represented by wedges in a circle and are proportional in size to the percent of individuals in each category.\nIn a bar graph, the length of the bar for each category is proportional to the number or percent of individuals in each category. Bars may be vertical or horizontal.\nA Pareto chart consists of bars that are sorted into order by category size (largest to smallest).\n\nggplot()\n\nIt is a good idea to look at a variety of graphs to see which is the most helpful in displaying the data. We might make different choices of what we think is the “best” graph depending on the data and the context. Our choice also depends on what we are using the data for.",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Data, Sampling, and Variation in Data and Sampling Data"
    ]
  },
  {
    "objectID": "ibs/ch02-data-sampling-variation.html#percentages-that-add-to-more-or-less-than-100",
    "href": "ibs/ch02-data-sampling-variation.html#percentages-that-add-to-more-or-less-than-100",
    "title": "Data, Sampling, and Variation in Data and Sampling Data",
    "section": "Percentages That Add to More (or Less) Than 100%",
    "text": "Percentages That Add to More (or Less) Than 100%\nSometimes percentages add up to be more than 100% (or less than 100%). In the graph, the percentages add to more than 100% because students can be in more than one category. A bar graph is appropriate to compare the relative size of the categories. A pie chart cannot be used. It also could not be used if the percentages added to less than 100%.",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Data, Sampling, and Variation in Data and Sampling Data"
    ]
  },
  {
    "objectID": "ibs/ch02-data-sampling-variation.html#omitting-categoriesmissing-data",
    "href": "ibs/ch02-data-sampling-variation.html#omitting-categoriesmissing-data",
    "title": "Data, Sampling, and Variation in Data and Sampling Data",
    "section": "Omitting Categories/Missing Data",
    "text": "Omitting Categories/Missing Data\nThe table displays Ethnicity of Students but is missing the “Other/Unknown” category. This category contains people who did not feel they fit into any of the ethnicity categories or declined to respond. Notice that the frequencies do not add up to the total number of students. In this situation, create a bar graph and not a pie chart.",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Data, Sampling, and Variation in Data and Sampling Data"
    ]
  },
  {
    "objectID": "ibs/ch02-data-sampling-variation.html#sampling",
    "href": "ibs/ch02-data-sampling-variation.html#sampling",
    "title": "Data, Sampling, and Variation in Data and Sampling Data",
    "section": "Sampling",
    "text": "Sampling\n\nSimple Random Sample\nGathering information about an entire population often costs too much or is virtually impossible. Instead, we use a sample of the population. A sample should have the same characteristics as the population it is representing. Most statisticians use various methods of random sampling in an attempt to achieve this goal. This section will describe a few of the most common methods.\nThere are several different methods of random sampling. In each form of random sampling, each member of a population initially has an equal chance of being selected for the sample. Each method has pros and cons. The easiest method to describe is called a simple random sample. Any group of \\(n\\) individuals is equally likely to be chosen as any other group of \\(n\\) individuals if the simple random sampling technique is used. In other words, each sample of the same size has an equal chance of being selected.\nFor example, suppose Lisa wants to form a four-person study group (herself and three other people) from her pre-calculus class, which has 31 members not including Lisa. To choose a simple random sample of size three from the other members of her class, Lisa could put all 31 names in a hat, shake the hat, close her eyes, and pick out three names. A more technological way is for Lisa to first list the last names of the members of her class together with a two-digit number:\n\n\n\nID\nName\nID\nName\nID\nName\n\n\n\n\n00\nAnselmo\n11\nKing\n21\nRoquero\n\n\n\n01 Bautista 12 Legeny 22 Roth 02 Bayani 13 Lundquist 23 Rowell 03 Cheng 14 Macierz 24 Salangsang 04 Cuarismo 15 Motogawa 25 Slade 05 Cuningham 16 Okimoto 26 Stratcher 06 Fontecha 17 Patel 27 Tallai 07 Hong 18 Price 28 Tran 08 Hoobler 19 Quizon 29 Wai 09 Jiao 20 Reyes 30 Wood 10 Khan\nLisa can use a table of random numbers (found in many statistics books and mathematical handbooks), a calculator, or a computer to generate random numbers. The numbers generated are as follows:\n\\[0.94360; 0.99832; 0.14669; 0.51470; 0.40581; 0.73381; 0.04399\\]\nLisa reads two-digit groups until she has chosen three class members (that is, she reads 0.94360 as the groups 94, 43, 36, 60). Each random number may only contribute one class member. If she needed to, Lisa could have generated more random numbers.\nThe random numbers \\(0.94360\\) and \\(0.99832\\) do not contain appropriate two digit numbers. However the third random number, \\(0.14669\\), contains \\(14\\) (the fourth random number also contains \\(14\\)), the fifth random number contains \\(05\\), and the seventh random number contains \\(04\\). The two-digit number \\(14\\) corresponds to Macierz, \\(05\\) corresponds to Cuningham, and \\(04\\) corresponds to Cuarismo. Besides herself, Lisa’s group will consist of Marcierz, Cuningham, and Cuarismo.\nBesides **simple random sampling*, there are other forms of sampling that involve a chance process for getting the sample. Other well-known random sampling methods are the stratified sample, the **cluster sample*, and the systematic sample.\n\n\nStratified Sample\nTo choose a stratified sample, divide the population into groups called strata and then take a proportionate number from each stratum. For example, you could stratify (group) your college population by department and then choose a proportionate simple random sample from each stratum (each department) to get a stratified random sample. To choose a simple random sample from each department, number each member of the first department, number each member of the second department, and do the same for the remaining departments. Then use simple random sampling to choose proportionate numbers from the first department and do the same for each of the remaining departments. Those numbers picked from the first department, picked from the second department, and so on represent the members who make up the stratified sample.\n\n\nCluster Sample\nTo choose a cluster sample, divide the population into clusters (groups) and then randomly select some of the clusters. All the members from these clusters are in the cluster sample. For example, if you randomly sample four departments from your college population, the four departments make up the cluster sample. Divide your college faculty by department. The departments are the clusters. Number each department, and then choose four different numbers using simple random sampling. All members of the four departments with those numbers are the cluster sample.\n\n\nSystematic Sample\nTo choose a systematic sample, randomly select a starting point and take every nth piece of data from a listing of the population. For example, suppose you have to do a phone survey. Your phone book contains 20,000 residence listings. You must choose 400 names for the sample. Number the population 1–20,000 and then use a simple random sample to pick a number that represents the first name in the sample. Then choose every fiftieth name thereafter until you have a total of 400 names (you might have to go back to the beginning of your phone list). Systematic sampling is frequently chosen because it is a simple method.\nA type of sampling that is non-random is convenience sampling. Convenience sampling involves using results that are readily available. For example, a computer software store conducts a marketing study by interviewing potential customers who happen to be in the store browsing through the available software. The results of convenience sampling may be very good in some cases and highly biased (favor certain outcomes) in others.\nSampling data should be done very carefully. Collecting data carelessly can have devastating results. Surveys mailed to households and then returned may be very biased (they may favor a certain group). It is better for the person conducting the survey to select the sample respondents.\nTrue random sampling is done with replacement. That is, once a member is picked, that member goes back into the population and thus may be chosen more than once. However for practical reasons, in most populations, simple random sampling is done without replacement. Surveys are typically done without replacement. That is, a member of the population may be chosen only once. Most samples are taken from large populations and the sample tends to be small in comparison to the population. Since this is the case, sampling without replacement is approximately the same as sampling with replacement because the chance of picking the same individual more than once with replacement is very low.\nSampling without replacement instead of sampling with replacement becomes a mathematical issue only when the population is small.\nWhen you analyze data, it is important to be aware of sampling errors and nonsampling errors. The actual process of sampling causes sampling errors. For example, the sample may not be large enough. Factors not related to the sampling process cause nonsampling errors. A defective counting device can cause a nonsampling error.\nIn reality, a sample will never be exactly representative of the population so there will always be some sampling error. As a rule, the larger the sample, the smaller the sampling error.\nIn statistics, a sampling bias is created when a sample is collected from a population and some members of the population are not as likely to be chosen as others (remember, each member of the population should have an equally likely chance of being chosen). When a sampling bias happens, there can be incorrect conclusions drawn about the population that is being studied.\nCritical Evaluation We need to evaluate the statistical studies we read about critically and analyze them before accepting the results of the studies. Common problems to be aware of include:\nProblems with samples: A sample must be representative of the population. A sample that is not representative of the population is biased. Biased samples that are not representative of the population give results that are inaccurate and not valid.\nSelf-selected samples: Responses only by people who choose to respond, such as call-in surveys, are often unreliable.\nSample size issues: Samples that are too small may be unreliable. Larger samples are better, if possible. In some situations, having small samples is unavoidable and can still be used to draw conclusions. Examples: crash testing cars or medical testing for rare conditions\nUndue influence: collecting data or asking questions in a way that influences the response\nNon-response or refusal of subject to participate: The collected responses may no longer be representative of the population. Often, people with strong positive or negative opinions may answer surveys, which can affect the results.\nCausality: A relationship between two variables does not mean that one causes the other to occur. They may be related (correlated) because of their relationship through a different variable.\nSelf-funded or self-interest studies: A study performed by a person or organization in order to support their claim. Is the study impartial? Read the study carefully to evaluate the work. Do not automatically assume that the study is good, but do not automatically assume the study is bad either. Evaluate it on its merits and the work done.\nMisleading use of data: improperly displayed graphs, incomplete data, or lack of context\nConfounding: When the effects of multiple factors on a response cannot be separated. Confounding makes it difficult or impossible to draw valid conclusions about the effect of each factor.\nVariation in Data\nVariation is present in any set of data. For example, 16-ounce cans of beverage may contain more or less than 16 ounces of liquid. In one study, eight 16 ounce cans were measured and produced the following amount (in ounces) of beverage:\n15.8; 16.1; 15.2; 14.8; 15.8; 15.9; 16.0; 15.5\nMeasurements of the amount of beverage in a 16-ounce can may vary because different people make the measurements or because the exact amount, 16 ounces of liquid, was not put into the cans. Manufacturers regularly run tests to determine if the amount of beverage in a 16-ounce can falls within the desired range.\nBe aware that as you take data, your data may vary somewhat from the data someone else is taking for the same purpose. This is completely natural. However, if two or more of you are taking the same data and get very different results, it is time for you and the others to reevaluate your data-taking methods and your accuracy.\n\n\nVariation in Samples It was mentioned previously that two or more samples from the same population, taken randomly, and having close to the same characteristics of the population will likely be different from each other. Suppose Doreen and Jung both decide to study the average amount of time students at their college sleep each night. Doreen and Jung each take samples of 500 students. Doreen uses systematic sampling and Jung uses cluster sampling. Doreen’s sample will be different from Jung’s sample. Even if Doreen and Jung used the same sampling method, in all likelihood their samples would be different. Neither would be wrong, however.\nThink about what contributes to making Doreen’s and Jung’s samples different.\nIf Doreen and Jung took larger samples (i.e. the number of data values is increased), their sample results (the average amount of time a student sleeps) might be closer to the actual population average. But still, their samples would be, in all likelihood, different from each other. This variability in samples cannot be stressed enough.\nSize of a Sample The size of a sample (often called the number of observations, usually given the symbol n) is important. The examples you have seen in this book so far have been small. Samples of only a few hundred observations, or even smaller, are sufficient for many purposes. In polling, samples that are from 1,200 to 1,500 observations are considered large enough and good enough if the survey is random and is well done. Later we will find that even much smaller sample sizes will give very good results. You will learn why when you study confidence intervals.\nBe aware that many large samples are biased. For example, call-in surveys are invariably biased, because people choose to respond or not.",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Data, Sampling, and Variation in Data and Sampling Data"
    ]
  },
  {
    "objectID": "ibs/ch18-linear-correlation.html",
    "href": "ibs/ch18-linear-correlation.html",
    "title": "Linear Correlation Coefficient Test",
    "section": "",
    "text": ". Each student (selected for the study) is measured for height and weight. Can we say (from this sample) that there is a link between student weight and height?\nEach driver (selected for the study) is measured for age and the number of car accidents he or she has had. Can we say (from this sample) that there is a link between age and the number of driver accidents? Etc…\nIt is assumed in this lesson that two quantitative variables are measured simultaneously in a population. (For example: height and weight or age and number of accidents)\nThe goal remains the same as when we studied the Chi-square test, that is: Study the possible link between these two variables.\nIn other words, the linear correlation coefficient test is used to study the existence or not of a link between two quantitative variables in a given population.\nModeling Framework : Population Variables studied simultaneously: X and Y real random variables (i.e. both variables are quantitative) Postulate: the couple Z = (X,Y) has an « L » Distribution Goal: to study the dependence between X and Y The unknown value :   ρ (X,Y)\nWe want to test H0 : ρ (X,Y) = 0 against H1 : ρ (X,Y) ≠ 0\nThe above test is a two-tailed test. It allows us to implicitly study the link between two variables. In other words, the acceptance of H1 implies the existence of a link between the two variables.\nWe want to test H0 : ρ (X,Y) = 0 against H1 : ρ (X,Y) ≠ 0\nIt is assumed that (X,Y) follows a bivariate Normal distribution. This restriction is less restrictive when the sample size n is large enough (e.g. ≥ 30)\n\n1 Notations\n\n𝑛 is the total number of data 𝑥 ̅ is the mean of the variable X 𝑠(𝑥 )is the standard deviation of the variable X 𝑦 ̅ is the mean of the variable Y 𝑠(𝑦 )is the standard deviation of the variable Y\n𝐶𝑜𝑣 (𝑥,𝑦)=1/𝑛 ∑2(𝑖=1)^𝑛▒〖𝑥𝑖 𝑦𝑖 〗 −(𝑥 ̅×𝑦 ̅) 𝑟(𝑥,𝑦)=(𝐶𝑜𝑣 (𝑥,𝑦))/(𝑠𝑥×𝑠_𝑦 )\nReminder Calculation of the Covariance Data at a raw state : 𝐶𝑜𝑣 (𝑥,𝑦)=1/𝑛 ∑2(𝑖=1)^𝑛▒〖𝑥𝑖 𝑦_𝑖 〗 −(𝑥 ̅×𝑦 ̅)\nExample : In this example, we find :\n𝑥 ̅=1624,8\n𝑦 ̅=1658,4\n𝐶𝑜𝑣 (𝑥,𝑦)=1/5(1624×1667+1625×1652+1622×1654+1613×1656+1640×1663−(1624,8×1658,4)=20,48\nReminder Calculation of the Covariance Data in a contingency table : 𝐶𝑜𝑣 (𝑥,𝑦)=1/𝑛 ∑2(𝑖=1)^𝑛▒〖〖𝑛𝑖𝑗 𝑥〗𝑖 𝑦𝑖 〗 −(𝑥 ̅×𝑦 ̅ )\nExample :\n𝐶𝑜𝑣 (𝑥,𝑦)= 1/20[(5×1×1+1×(−0,25)×1+1×(−0,25)×1+2×(−0,25)×(−0,25)] −(0,3×0,55) = 0.06625\n\n2 The formulas to perform the test The following expression must be calculated:\n\nWhere\nDecision rule: We reject H0 if |uobs | ≥ t, otherwise we do not reject H0 The rejection of H0 implies the acceptance of H1 and consequently we can deduce the dependence of the variables. The non-rejection of H0 does not necessarily imply the absence of a link between X and Y .\nwhere t is defined as follows F(t) = 1−𝛼/2, where F is the distribution function of the Student’s distribution, with n-2 degrees of freedom\nt is calculated from the Student’s distribution table.\nStudent Distribution Table\nwith\n𝟏−𝜶/𝟐 Degrees of freedom = n-2\nWhen the sample size is sufficiently large (e.g. ≥ 30), the decision rule for the test becomes:\nWe reject H0 if |uobs| &gt; u , otherwise we do not reject H0\nwhere u is a real defined as follows F(u) = 1−𝛼/2, with F is the distribution function of the normal distribution\nu is calculated from the table of the Normal distribution.\nNormal Distribution Table\nwith\n𝟏−𝜶/𝟐\n\n3 Conclusion of the test\n\nAs a reminder, the test is written : H0 : ρ (X,Y) = 0 against H1 : ρ (X,Y) ≠ 0\nH0 rejected : the data confirm that the two variables are not independent  This implies that there is a link between the two variables\nH0 not rejected : the data do not confirm that the two variables are not independent  In other words, the data do not confirm a link between the two variables with an α% risk.\nLet X be the net salary of women and Y the net salary of men in the same household. It is assumed that the couple (X,Y) follows a normal distribution. The two variables are studied on 15 households. The results are presented in the following table:\nAt the 5% risk, can we say that there is a link between salaries and gender?\nThe test is written:\nH0 : ρ (X,Y) = 0\n    against\nH1 : ρ (X,Y) ≠ 0\n\n1 Notations\n\n𝑛 is the total number of data  n = 15 &lt; 30 𝑥 ̅ is the mean of the variable X  𝑥 ̅ = 1/15 (1624+…+1613)= 1631,93 𝑠(𝑥 ) is the standard deviation of the variable X  𝑠𝑥=√(1/15 (〖1624〗2+…+〖1613〗2 )−1631,93²)=√247,79=15,74 𝑦 ̅ is the mean of the variable Y  𝑦 ̅ = 1/15 (1667+…+1667)= 1670 𝑠(𝑦 ) is the standard deviation of the variable Y  𝑠𝑦=√(1/15 (〖1667〗2+…+〖1667〗2 )−1670²)=√254,54=15,95\n𝐶𝑜𝑣 (𝑥,𝑦)=1/𝑛 ∑2(𝑖=1)^𝑛▒〖𝑥𝑖 𝑦𝑖 〗 −(𝑥 ̅×𝑦 ̅ )= 1/15(1624×1667+…+1613×1667) −(1631,93×1670)=196,73 𝑟(𝑥,𝑦)=(𝐶𝑜𝑣 (𝑥,𝑦))/(𝑠𝑥×𝑠_𝑦 ) = 196,73/(15,74×15,95) = 196,73/251,05=0,78\n\n2 The formulas to perform the test\n\nThe following expression must be calculated:\nIn our example:\nStudent Distribution Table\nwith\n𝟏−𝜶/𝟐 = 𝟏−(𝟎,𝟎𝟓)/𝟐=𝟎,𝟗𝟕𝟓 Degrees of freedom = n-2 = 15-2=13\nWe find t = 2,16\n\n3 Conclusion of the test\n\nWith a risk α = 5%, we reject the H0 hypothesis.\nIn other words, with a 5% risk, the data confirm that there is a link between women’s salary and men’s salary within the same household. So, there is a link between the salaries and the gender.\nA famous brand specialized in the distribution of cultural and electronic products to the general public has commissioned a study from a firm specialized in marketing. The goal is to study the existence of a link between the amount spent and the age of the store’s customers. A survey was conducted on a sample of 120 customers. Let 𝑥𝑖 be the amount spent by the ith customer and 𝑦𝑖 represent their age. We obtain the following results:\nAt 1% risk, can we say that the age and the amount spent are linked ?\nThe test is written:\nH0 : ρ (X,Y) = 0\n    against\nH1 : ρ (X,Y) ≠ 0\nLet X be the variable dedicated to the amount spent Let Y be the variable dedicated to the age of the client\n\n1 Notations\n\n𝑛 is the total number of data  n = 120 &gt; 30 𝑥 ̅ is the mean of the variable X  𝑥 ̅ = 1/120×2956= 24,63 𝑠(𝑥 ) is the standard deviation of the variable X  𝑠𝑥=√(1/120 75752−24,63²)=√24,46=4,95 𝑦 ̅ is the mean of the variable Y  𝑦 ̅ = 1/120×4383= 36,525 𝑠(𝑦 ) is the standard deviation of the variable Y  𝑠𝑦=√(1/120 164699−36,525²)=√38,416=6,198\n𝐶𝑜𝑣 (𝑥,𝑦)=1/𝑛 ∑2(𝑖=1)^𝑛▒〖𝑥𝑖 𝑦𝑖 〗 −(𝑥 ̅×𝑦 ̅ )= 1/120(111464) −(24,63×36,525)=29,26 𝑟(𝑥,𝑦)=(𝐶𝑜𝑣 (𝑥,𝑦))/(𝑠𝑥×𝑠_𝑦 ) = 29,26/(4,95×6,198) = 29,26/30,68=0,95\n\n2 The formulas to perform the test The following expression must be calculated :\n\nIn our example:\nNormal Distribution Table\nwith\n𝟏−𝜶/𝟐 = 0,995\nWe obtain u = 2,58\n\n3 Conclusion of the test\n\nWith a risk α = 1%, we reject the hypothesis H0 The two variables are not independent.\nIn other words, with a 1% risk, the data confirms that there is a link between the amount spent by a customer and their age.\n\n13 / exercice\nThe data below shows the height and high jump score of 40 athletes.\nAt the 1% risk, can we say that the size and the sports result of the athletes (specialized in high jump) are linked?\nThe test is written:\nH0 : ρ (X,Y) = 0\n    against\nH1 : ρ (X,Y) ≠ 0\nLet X be the variable dedicated to the size of the athletes Let Y be the variable dedicated to the sports result\n\nNotations\n\n𝑛 is the total number of data  n = 40 &gt; 30 𝑥 ̅ is the mean of the variable X  𝑥 ̅ = 1/40 (1,73+…+1,84)= 1,818 𝑠(𝑥 ) is the standard deviation of the variable X  𝑠𝑥=√(1/40 (〖1,73〗2+…+〖1,84〗2 )−1,818²)=√0,0104=0,102 𝑦 ̅ is the mean of the variable Y  𝑦 ̅ = 1/40 (2,32+…+2,37)= 2,3725 𝑠(𝑦 ) is the standard deviation of the variable Y  𝑠𝑦=√(1/40 (〖2,32〗2+…+〖2,37〗2 )−3,3725²)=√0,0022=0,047\n𝐶𝑜𝑣 (𝑥,𝑦)=1/𝑛 ∑2(𝑖=1)^𝑛▒〖𝑥𝑖 𝑦𝑖 〗 −(𝑥 ̅×𝑦 ̅ )= 1/40(1,73×2,32+…+1,84×2,37) −(1,818×2,3725)=0,0043125 𝑟(𝑥,𝑦)=(𝐶𝑜𝑣 (𝑥,𝑦))/(𝑠𝑥×𝑠_𝑦 ) = 0,0043125/(0,102×0,047) = 0,0043125/0,0048=0,89\n\nThe formulas to perform the test The following expression must be calculated:\n\nIn our example:\nThe Normal Distribution Table\nwith\n𝟏−𝜶/𝟐 = 0,995\nWe obtain u = 2,58\n\nConclusion of the test\n\nWith a risk α = 1%, we reject the hypothesis H0 The two variables are not independent.\nIn other words, with a 1% risk, the data confirm that there is a link between the athlete’s height and sports performance.\n\n\n13 / moodle\nWe consider the 1 to 4 Likert scale to measure customer satisfaction. The data below show the satisfaction level of 440 randomly selected customers with two products P1 and P2 belonging to two competing brands.\nIf we want to know if there is a link between the level of customer satisfaction with the two products, what hypothesis test can be used?\nA test of conformity to a reference average  A comparison test between two means ANOVA Test Chi-square test\nWe consider the 1 to 4 Likert scale to measure customer satisfaction. The data below show the satisfaction level of 440 randomly selected customers with two products P1 and P2 belonging to two competing brands.\nWhat is the mean level of satisfaction for the product P1 ?\n1,5 2,5 3,5 4,5\nWe consider the 1 to 4 Likert scale to measure customer satisfaction. The data below show the satisfaction level of 440 randomly selected customers with two products P1 and P2 belonging to two competing brands.\nWhat is the mean level of satisfaction of the product P2 ?\n1,41 2,41 3,41 4,41\nWe consider the 1 to 4 Likert scale to measure customer satisfaction. The data below show the satisfaction level of 440 randomly selected customers with two products P1 and P2 belonging to two competing brands.\nWhat is the value of the empirical linear correlation coefficient : r(x,y) ?\n-0,81 -0,41 0,41 0,81\nWe consider the 1 to 4 Likert scale to measure customer satisfaction. The data below show the satisfaction level of 440 randomly selected customers with two products P1 and P2 belonging to two competing brands.\nWhat is the value of 𝑢_𝑜𝑏𝑠 ?\n0,46 9,48 78,46 248,46\nWe consider the 1 to 4 Likert scale to measure customer satisfaction. The data below show the satisfaction level of 440 randomly selected customers with two products P1 and P2 belonging to two competing brands. At the 1% risk, can we say that there is a link between the level of customer satisfaction with the two products?\nTo solve such a hypothesis test, which table can be used ? Normal Distribution Table Fisher Table Chi-Square Table\nWe consider the 1 to 4 Likert scale to measure customer satisfaction. The data below show the satisfaction level of 440 randomly selected customers with two products P1 and P2 belonging to two competing brands. At the 1% risk, can we say that there is a link between the level of customer satisfaction with the two products?\nIn such a hypothesis test, what is the value of u ? 0,99 0,995 1,37 2,58\nWe consider the 1 to 4 Likert scale to measure customer satisfaction. The data below show the satisfaction level of 440 randomly selected customers with two products P1 and P2 belonging to two competing brands. At the 1% risk, can we say that there is a link between the level of customer satisfaction with the two products?\nThe data confirm a link between the level of satisfaction of the product P1 and that of P2 The data do not confirm a link between the level of satisfaction with P1 and P2",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Linear Correlation Coefficient Test"
    ]
  },
  {
    "objectID": "ibs/ch09-probabilities.html",
    "href": "ibs/ch09-probabilities.html",
    "title": "Calculation of probabilities",
    "section": "",
    "text": "Maîtrisez les bases des probabilités\nPractical approach: Probability allows to measure the likelihood of an event. Some definitions : Random experiment: an experiment (involving chance) whose results can not be predicted with certainty Universe: the set of all possible outcomes of a random experiment, noted Ω Event: a part or subset of the universe\nProbability: a number between 0 and 1 that gives a measure of the likelihood of an event. In other words, if 𝐸 is an event, then\n0 ≤ ℙ(𝐸) ≤ 1 Special cases of events: Certain event: it can be described with all the elements of Ω and in that case its probability is 1 Impossible event: there exist no element of Ω which can describe it and in that case its probability is 0\nProperties and basic operations:\nInclusion : 𝐴 ⊂ 𝐵 ⇒ ℙ(𝐴) ≤ ℙ(𝐵) Intersection : ℙ(𝐴 ∩ 𝐵) ≤ ℙ(𝐵) and ℙ(𝐴 ∩ 𝐵) ≤ ℙ(𝐴) If ℙ(𝐴 ∩ 𝐵) = ℙ(𝐴) × ℙ(𝐵), then 𝐴 and 𝐵 are two independent events If 𝐴 and 𝐵 are disjoint (i.e. 𝐴 ∩ 𝐵 = ∅ ), then ℙ(𝐴 ∩ 𝐵) = 0\nUnion : ℙ (𝐴)≤ℙ(𝐴∪𝐵), ℙ(𝐵) ≤ ℙ(𝐴∪𝐵) and ℙ(𝐴∩𝐵) ≤ ℙ(𝐴∪𝐵) ℙ(𝐴 ∪ 𝐵)= ℙ(𝐴)+ ℙ(𝐵)− ℙ(𝐴 ∩ 𝐵) Therefore, if 𝐴 and 𝐵 are two disjoint events, then ℙ(𝐴 ∪ 𝐵) = ℙ(𝐴) + ℙ(𝐵) The difference : (𝐴∖𝐵) ⊂ 𝐴 ⇒ ℙ(𝐴∖𝐵) ≤ ℙ(𝐴) ℙ(𝐴∖𝐵) = ℙ(𝐴) − ℙ(𝐴 ∩ 𝐵) If 𝐴 and 𝐵 are two disjoint events, then (𝐴∖𝐵) = 𝐴. Therefore, one gets ℙ(𝐴∖𝐵) = ℙ(𝐴).\nComplementarity : The complement of the event 𝐴 is an event (denoted 𝐴 ̅ or Ω∖𝐴) that contains all elements of Ω not belonging to 𝐴\n\\[P(\\overline{A}) = 1 - P(A)\\]\nEquiprobability\nAssume that the universe \\(\\Omega\\) of a random experiment is a finite set. We talk of equiprobability when all the possible outcomes of the experiment have the same probability (of realization). Let \\(A\\) be an event associated with this experiment. In that case, we have:\n\\[P(𝐴) = \\frac{\\text{Number of favorable cases}}{\\text{Number of possible cases}}\\]\nThe conditional probability\nLet \\(A\\) and \\(B\\), two events from the same universe \\(\\Omega\\). Suppose that \\(A\\) is a non-zero probability event. We call conditional probability of \\(B\\) such \\(A\\) (or knowing that \\(A\\) is realized) the quantity defined as follows:\n\\[P(B \\vert A) = \\frac{P(A \\cap B)}{P(A)}\\]\nIn the same way, the conditional probability of \\(A\\) such \\(B\\) (or knowing that \\(B\\) is realized) is defined by:\n\\[P(A \\vert B) = \\frac{P(A \\cap B)}{P(B)}\\]\nIf \\(A\\) and \\(B\\) are two independent events, then:\n\\[P(A \\vert B) = P(𝐴)\\]\n\\[P(B \\vert A) = P(B)\\]\nTotal Probability Formula:\nLet \\(\\{𝐸1, ..., 𝐸_𝑘\\}\\) be a partition of \\(\\Omega\\) (such that 𝐸_𝑖 ≠ ∅ for all 𝑖 = 1,…,𝑘) Let 𝐵 be an event. We have :\n“ℙ” (𝐵)= ∑*𝑖\nIn the event of a technical problem three out of five companies use an external provider, two out of five try to find a solution by using internal resources. With the external provider, 75% of the companies are satisfied. With the use of internal resources, 90% of the companies are satisfied.\nWhat is the overall rate of satisfied companies ? What is the probability for a company to have used an external service provider knowing that it is satisfied ?\nIn the event of a technical problem three out of five companies use an external provider, two out of five try to find a solution by using internal resources. With the external provider, 75% of the companies are satisfied. With the use of internal resources, 90% of the companies are satisfied.\nConsider the following events A : company that uses an external provider B : company that uses internal resources S : satisfied company\nWhat is the overall rate of satisfied companies : “ℙ” (𝑆)=“ℙ” 𝐴 (𝑆)× “ℙ” (𝐴)+“ℙ” 𝐵 (𝑆)×” ℙ” (𝐵)=0,81\nWhat is the probability for a company to have used an external service provider knowing that it is satisfied : “ℙ” 𝑆 (𝐴)=“ℙ” (𝐴 ∩𝑆)/“ℙ” (𝑆) =(“ℙ” 𝐴 (𝑆)×” ℙ” (𝐴))/(“ℙ” (𝑆))=55,6%\nWe know that 35% of the employees of a company have taken traineeship A, 25% have taken traineeship B and 15% have completed both. An employee is randomly interviewed. What is the probability that this person has taken at least one of the two traineeships? What is the probability that this person has not taken any traineeship? What is the probability that this person has completed one and only one of the traineeships? An employee who has taken traineeship A is interviewed. What is the probability that this person has completed traineeship B as well? An employee who has completed traineeship B is interviewed. What is the probability that this person has completed traineeship A as well? Is taking traineeship A independent of taking traineeship B?\nConsider the following events : A = the employee has taken traineeship A : ℙ (A) = 0.35 B = the employee has taken traineeship B : ℙ (B) = 0.25 A ∩ B = the employee has taken both traineeships : ℙ(A ∩ B)=0,15\nℙ(A ∪ B)= ℙ(A)+ ℙ(B)− ℙ(A ∩ B)=0,45 ℙ((A ∪ B) ̅ )=1−ℙ(A ∪ B)=0,55 ℙ(A ∪ B)−ℙ(A ∩ B)=0,3 “ℙ” _A (B) =“ℙ”(B | A) =“ℙ” (A ∩ B)/“ℙ” (A) =0,15/0,35=0,43 “ℙ” _B (A)=“ℙ” (A│B)=“ℙ” (A ∩ B)/“ℙ” (B) = 0,15/0,25=0,6 ℙ(A ∩ B)≠ ℙ(A)× ℙ(B), therefore A and B are not independent",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Calculation of probabilities"
    ]
  },
  {
    "objectID": "ibs/ch09-probabilities.html#can-you-roll-the-dungeon-masters-dice",
    "href": "ibs/ch09-probabilities.html#can-you-roll-the-dungeon-masters-dice",
    "title": "Calculation of probabilities",
    "section": "Can You Roll the Dungeon Master’s Dice?",
    "text": "Can You Roll the Dungeon Master’s Dice?\n\nThis Week’s Fiddler\nFrom Julien Beasley comes a coincidence of dice:\nTwo people are sitting at a table together, each with their own bag of six “DnD dice”: a d4, a d6, a d8, a d10, a d12, and a d20. Here, “dX” refers to a die with X faces, numbered from 1 to X, each with an equally likely probability of being rolled.\nBoth people randomly pick one die from their respective bags and then roll them at the same time. For example, suppose the two dice selected are a d4 and a d12. The players roll them, and let’s further suppose that both rolls come up as 3. What luck!\nWhat’s the probability of something like this happening? That is, what is the probability that both players roll the same number, whether or not they happened to pick the same kind of die?\n\n\nSolution\nCongratulations to the (randomly selected) winner from last week: 🎻 Nigel 🎻 from Sanderstead, England. I received 81 timely submissions, of which 60 were correct—good for a 74 percent solve rate. I was pleased to see a very healthy increase in the number of solvers as compared to two weeks ago. Way to bounce back, everyone!\nLast week, two people were sitting at a table together, each with their own bag of six “DnD dice”: a d4, a d6, a d8, a d10, a d12, and a d20. Here, “dX” referred to a die with X faces, numbered from 1 to X, each with an equally likely probability of being rolled.\nBoth people randomly picked one die from their respective bags and then rolled them at the same time. For example, suppose the two dice selected were a d4 and a d12. The players rolled them, and both rolls come up as 3. What luck!\nWhat was the probability of something like this happening? That is, what was the probability that both players rolled the same number, whether or not they happened to pick the same kind of die?\nA good first step was to work out the probability of rolling each number. For example, what was the probability of rolling a 20?\nTo figure this out, many readers counted up the faces on all the dice. The d4 had 4 faces, the d6 had 6 faces, and so on. In total, there were 60 faces. Only one of these was a 20, which meant the probability of rolling a 20 was 1/60. Right?\nNot quite. Why? By this logic, you had a 4-in-60 chance of picking the d4, a 6-in-60 chance of picking the d6, and so on. However, the puzzle said that each player picked a die at random, implying that each die had the same 1-in-6 chance of being selected. So the probability of rolling a 20 was not in fact 1/60. First, you needed to pick the d20 (a 1-in-6 chance) and then, given that you were rolling the d20, you needed to actually roll a 20 (a 1-in-20 chance). Combining these meant the probability of rolling a 20 was in fact (1/6)·(1/20), or 1/120. The probability was the same for rolling 19, 18, 17, 16, 15, 14, and 13.\nMeanwhile, your chances of rolling a 12 were greater, since there were two dice, the d20 and the d12, that could have resulted in a 12. As before, you had a 1-in-20 chance of picking the d20 and a 1-in-20 chance of then rolling the 12. But this time, you also had a 1-in-6 chance of picking the d12 and a 1-in-12 chance of then rolling a 12. Combining these cases meant the probability of rolling a 12 was (1/6)·(1/20) + (1/6)·(1/12), which simplified to 1/120 + 1/72, or 1/45. The probability was the same for rolling 11.\nContinuing in this fashion (i.e., adding up the respective probabilities of the dice that could have resulted in each roll), you got the following:\nThe probability of rolling 20, 19, 18, 17, 16, 15, 14, or 13 was 1/120.\nThe probability of rolling a 12 or 11 was 1/45.\nThe probability of rolling a 10 or 9 was 7/180.\nThe probability of rolling an 8 or 7 was 43/720.\nThe probability of rolling a 6 or 5 was 7/80.\nThe probability of rolling a 4, 3, 2, or 1 was 31/240.\nAt this point, I’d like to quickly note that you were more likely than not to roll a 1, 2, 3, or 4, as this collective probability was approximately 51.7 percent. I found that a little surprising.\nOkay, back to the puzzle. So far, we’ve worked out all the probabilities for one person’s roll. With two people rolling, you could determine the probability of each pair of rolls by creating a grid in which each row was one player’s roll and each column was the other player’s roll. Since the rolls were independent, the probability of the pair was the product of two respective probabilities.\nHere’s what that grid looked like, with likelier pairs shown in yellow:\n\nA grid in a spreadsheet. There are 20 rows, numbered from 1 to 20, representing the roll of the first player. There are also 20 columns, representing the roll of the second player. The respective probabilities of each roll are also shown. In the grid are 400 cells, with each cell showing the product of the probability from its row and column. The cells are color-coded, so that higher values appear yellower. Cells along the main diagonal have a thicker black border. The cells outlined in black along the main diagonal of the grid were precisely when both players rolled the same value. And so, the answer to the puzzle was the sum of these 20 cells, also known as the trace of the grid (or “matrix”).\nThe exact answer was 4(31/240)2 + 2(7/80)2 + 2(43/720)2 + 2(7/180)2 + 2(1/45)2 + 8(1/120)2, which simplified to 3/32, or 9.375 percent.\nSeveral solvers, like Sameer G. of Ithaca, New York, neatly arrived at the same result with a little less computation. Sameer worked out the probabilities with which the players had the same roll, for each possible pair of dice they picked. For example, if both players picked a d4, the probability they had the same roll was 1/4. If one picked a d4 and the other picked a d6, the probability was now 1/6. In general, if the two dice were dX and dY, the rolls were the same with probability 1/max(X, Y). Computing the average probability across all 36 possible pairs for X and Y, Sameer arrived at the same result of 3/32.\nIn the end, despite having six different dice to choose from, the probability that both players rolled the same number wasn’t too much less than it would have been if they had both rolled a standard die (i.e., d6). This was largely thanks to the fact that every die had the numbers 1 through 4, which accounted for the majority of the time the players had the same roll.",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Calculation of probabilities"
    ]
  },
  {
    "objectID": "ibs/ch15-hypothesis-testing-comparison-test.html",
    "href": "ibs/ch15-hypothesis-testing-comparison-test.html",
    "title": "Hypothesis testing - Comparison test",
    "section": "",
    "text": "The Department of Education looks at the average (first hire) salary of students graduating in 2021 (in higher education)\nIn particular, the Ministry wishes to compare the salaries of engineering school graduates with those of business school graduates\nIndeed, the department check whether on average :\nThere is a salary difference Engineering school graduates have an advantage Business school graduates have an advantage We note that in this context, there are no reference values. Thus, in order to answer the ministry’s questions, we have to compare two unknown averages.\nTransforming the problem into a modeling framework:\nUnknown parameters :\n𝑚_1=𝔼(𝑋_1) and 𝜎_1= 𝜎(𝑋_1) 〖 𝑚〗_2=𝔼(𝑋_2) and 𝜎_2= 𝜎(𝑋_2)\nThe department’s questions can be translated as follows:\nOn average, there is a difference in salary  𝒎𝟏 ≠𝒎𝟐 On average, the salary of engineering school graduates is better 〖 𝒎〗𝟏&gt;𝒎𝟐 On average, the salary of business school graduates is better  𝒎𝟏&lt;𝒎𝟐\nApproach 1 :\nIf we have perfect knowledge of the distributions “𝔏1” and “𝔏2”, then the problem becomes purely “probabilistic”\n Simply calculate 𝑚_1=𝔼(𝑋_1) and 〖 𝑚〗_2=𝔼(𝑋_2) (afterwards perform the comparison between the calculated means)\nApproach 2 :\nWe can proceed by census: in other words, study the unknown parameter(s) on the whole of each sub-population\nApproach 3 :\nWe can proceed by sampling: in other words, study the unknown parameter(s) on a part of each sub-population\nRemark :\nGiven that perfect knowledge of the “𝕷” distribution is rather utopian. The sampling procedure is often preferred for processing\nThis procedure allows to bypass a number of difficulties / disadvantages of the census procedure:\nAccessibility to the entire population The cost The time …\nThe “reliability” of this procedure obviously depends on the “selection quality” of the individuals and the number of individuals.\nStep 1 : calculation of the (empirical) test statistic\nWhere\n𝑥 ̅ is the empirical mean, 𝑠_𝑥 is the empirical standard deviation (calculated from data set 1)\n𝑦 ̅ is the empirical mean, 𝑠_𝑦 is the empirical standard deviation (calculated from data set 2)\nThe Ministry of Education wishes to check whether there is a difference in the average salary (of the first employment contract) between students graduating in 2021 (in higher education) from engineering schools and business schools\nTo do this, the Ministry conducted two separate empirical studies.\nIn the first study, the Ministry selected (randomly) 100 graduates (in 2021) from engineering schools and took their gross monthly salaries (from the first contract after graduation) . This first study gave an average of 3350 euros and a standard deviation of 400.\nIn the second study, the ministry selected (randomly) 120 graduates (in 2021) from business schools and took their gross monthly salaries (from the first contract after graduation). This first study gave an average of 3550 euro and a standard deviation of 650 .\nCan we say, with a 1% risk, that there is a difference in average salary (of the first hiring contract) between students graduating in 2021 from engineering schools and business schools?\nTransforming the problem into a modeling framework:\nUnknown parameters:\n𝑚_1=𝔼(𝑋_1) and 𝜎_1= 𝜎(𝑋_1) 〖 𝑚〗_2=𝔼(𝑋_2) and 𝜎_2= 𝜎(𝑋_2)\nFormulation: we wish to carry out a two-tailed test of comparison between two unknown means:\nTreatment in conclusion:\nCalculation of the (empirical) test statistic : 𝑢_𝑜𝑏𝑠=−2.794858\nWith 𝛼=1%, we have 𝑢=2.575. It implies that |𝑢_𝑜𝑏𝑠 |&gt;𝑢 Therefore, we reject the null hypothesis.\nIn other words, the data allow us to confirm, with a 1% risk, that there is a difference in average salary (of the first hiring contract) between students graduating in 2021 from engineering schools and business schools.\nThe French Ministry of Education is interested in the hiring rate following graduation (in higher education) among students of the class of 2021.\nIn particular, the Ministry wishes to compare this hiring rate between engineering school graduates and business school graduates\nIndeed, the department will check if :\nThere is a difference The hiring rate is higher for engineering school graduates The hiring rate is higher for business school graduates\nWe note that in this context, there are no reference values. Thus, in order to answer the ministry’s questions, we have to compare two unknown proportions\nTransforming the problem into a modeling framework:\nUnknown parameters :\n𝑝_1 = ℙ(𝑋_1 = 1) 𝑝_2 = ℙ(𝑋_2 = 1)\nThe department’s questions can be translated as follows:\nThe hiring rate is different  𝒑𝟏 ≠𝒑𝟐 The hiring rate is higher for engineering school graduates 〖 𝒑〗𝟏&gt;𝒑𝟐 The hiring rate is higher for business school graduates  𝒑𝟏&lt;𝒑𝟐\n\n09/exercices\nThe price of a product, noted PP, depends on the evolution of the price of fuel. The Ministry of Economy wishes to study the evolution of the price of the product PP between April 2022 and May 2022. To do this, the Ministry conducted two separate studies. Explicitly, the ministry randomly sampled 100 PP products during the month of April and 70 PP products during the month of May.\nWe have: 𝑥𝑖 the price of the ith PP product selected in April 𝑦𝑗 the price of the jth PP product selected in May\nLet’s assume that:\nQuestion :\nCan we confirm, with a 5% risk (then 10%), that the average price between April and May has decreased?\nEmpirical results (April data set):\nThe size of the data set : 𝑛1 = 100 (&gt; 30) The empirical mean (estimation of 𝑚_1= 𝔼(𝑋_1 )) : 𝑥 ̅ = 31.719 The empirical standard deviation (estimation of “σ” _1=“σ” (𝑋_1 )) : 𝑠𝑥 = √3.776309\nEmpirical results (May data set):\nThe size of the data set : 𝑛2 = 70 (&gt; 30) The empirical mean (estimation of 𝑚_2= 𝔼(𝑋_2 )) : 𝑦 ̅ = 31.36301 The empirical standard deviation (estimation of “σ” _2=“σ” (𝑋_2 )) : 𝑠𝑦 = √1.851842\nWe wish to perform a right one-tailed test of comparison between two means\nThe (empirical) test statistic : 𝑢_𝑜𝑏𝑠=1.404776\nA firm specialized in commercial strategy wishes to test the effectiveness of an advertisement broadcasted (with the same frequency, in the media and on social networks) on the whole French territory. In particular, the firm focuses on two distinct geographical areas, noted A and B. Three weeks after the ad was broadcast, the firm conducted two separate surveys.\nThe first study involved 1100 randomly selected people who had seen the ad (at least once) and who resided in area A. This study showed that 658 people remembered the slogan of the ad.\nThe second study was conducted with 1,000 randomly selected people who had seen the ad (at least once) and who resided in Area B. This study showed that 526 people remembered the slogan of the ad.\nQuestion :\nCan we confirm, with a 5% risk (then 1%), that advertising is more effective in the area A?\nEmpirical results (Area A dataset):\nThe size of the data set : 𝑛_1 = 1100 (&gt; 30) The number of people who remember the advertising slogan : 𝑘_1=658 The empirical proportion (estimation of 𝑝_1) : 𝑝 ̂_1=“0.5981818”\nEmpirical results (Area B dataset):\nThe size of the data set : 𝑛_2 = 1000 (&gt; 30) The number of people who remember the advertising slogan : 𝑘_2=526 The empirical proportion (estimation of 𝑝_2) : 𝑝 ̂_2=“0.526”\n\n\n09 / moodle\nExercise 1 :\nA laboratory proposes a new treatment to fight against overweight. The laboratory wishes to evaluate the effectiveness of its treatment according to the age of overweight people. To do this, the laboratory has conducted two separate studies. A first study was carried out with 70 young overweight people (between 20 and 30 years old) chosen at random. Following the treatment, the laboratory observed 40 good results in these participants. A second study was conducted with 100 randomly selected overweight people (over 65 years old). Following the treatment, the laboratory observed 43 good results in these participants. Thus, we can deduce that: Overweight people represent the study population A. True B. False\nFeedback : untreated overweight people are not part of the population.\nTo check if the treatment is more effective in young overweight people then a right one-tailed test of comparison between two means should be performed. A. True B. False\nFeedback : the “good outcome” rates are the unknowns.\n\nIf we wish to evaluate the treatment is more effective in younger overweight individuals, then the (empirical) test statistic, denoted 𝑢_𝑜𝑏𝑠, is equal to 2.88 A. True B. False\nFeedback : Check the calculations (using the formula to find the test statistic associated with a comparison test between two proportions)\nThe data allow us, with a 1% risk, to confirm that the treatment is more effective in young overweight people. A. True B. False\nFeedback : With a risk of 1%, we see that there is no rejection of the initial hypothesis ….\nThe data do not allow us, with a 5% risk, to confirm that the treatment is more effective in young overweight people. A. True B. False\nFeedback : With a risk of 5%, we find that the initial hypothesis is rejected ….\n\nExercise 2\nA factory manufactures steel cables. The plant’s quality manager wants to check t2. Let 𝑚_1 be the unknown average breaking load weight under low temperature and 𝑚_2 the unknown average breaking load weight under high temperature. To test whether the quality of the steel wire ropes manufactured at the factory is better under low temperature, a right one-tailed test of comparison between two unknown means is performed. A. True B. False\nFeedback : we put in the alternative hypothesis what we want to demonstrate\nhe breaking load that these cables can withstand as a function of the ambient temperature.\nTo do this, he has carried out two separate studies.\nFor the first study, the quality manager randomly selected 100 steel cables manufactured at the plant and measured their breaking loads at low temperatures (-2°C). This study gave an average of 58 tons and a standard deviation of 3 tons. For the second study, the quality manager randomly selected 120 steel cables manufactured at the plant and measured their breaking loads under high temperature (40°C). This study gave an average of 57 tons and a standard deviation of 5 tons.\nThus, we can deduce that:\n\nTo check if the quality of the steel wire ropes manufactured in the factory is better under low temperature, we have to perform a two-tailed comparison test between two unknown means. A. True B. False\nFeedback : the proposed test allows to check if the quality is different according to the temperature.\nThe data allows us, with a 5% risk, to confirm that the quality of the steel cables manufactured in the factory is better at low temperatures. A. True B. False\nFeedback : After checking the calculations (using the formula for finding the test statistic associated with a comparison test between two averages), we find that the initial hypothesis is rejected (with a 5% risk)\nThe data allows us, with a 1% risk, to confirm that the quality of the steel cables manufactured in the factory is better at low temperatures. A. True B. False\nFeedback : After checking the calculations (using the formula for finding the test statistic associated with a comparison test between two averages), we see that the initial hypothesis is not rejected (with a 1% risk)",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Hypothesis testing - Comparison test"
    ]
  },
  {
    "objectID": "ibs/ch11-continuous-random-variable.html",
    "href": "ibs/ch11-continuous-random-variable.html",
    "title": "Continuous random variable",
    "section": "",
    "text": "normal distribution real life examples\ngalton board simulation in python, R\n\nDéfinition A random variable 𝑋 is called continuous if 𝑋(Ω) is an interval of ℝ, i.e 𝑋(Ω) has one of the following forms: ]−∞,𝑎] , ]−∞,𝑎[ , ]𝑎,+∞[, [𝑎,+∞[ , ]−∞,+∞[ ,]𝑎,𝑏[ ,[𝑎,𝑏[ ,]𝑎,𝑏],[𝑎,𝑏]où 𝑎&lt;𝑏. Some examples : Time interval between 2 trains Hair length Lifetime in seconds of a mechanical part\nLet 𝑋 be a continuous random variable and 𝑋(Ω) be the set of its possible values.\nDensity function: 𝑓 : ℝ →ℝ is a density if it satisfies the following conditions: For all 𝑥∈ℝ, 𝑓(𝑥) ≥ 0 ∫_(−∞)^(+∞)▒〖𝑓 (𝑥)𝑑𝑥〗= 1\nNote that : For all 𝑥 ∈ℝ, ℙ(𝑋 = 𝑥) = 0 For all 𝑎, 𝑏 ∈ℝ with 𝑎 &lt; 𝑏, ℙ (𝑎≤𝑋≤𝑏)=ℙ(𝑋 ∈[𝑎,𝑏])= ∫_𝑎^𝑏▒〖𝑓 (𝑥)𝑑𝑥〗\nExpectation : 𝔼(𝑋)=∫(−∞)^(+∞)▒〖𝑥𝑓 (𝑥)𝑑𝑥〗 Variance : 𝕍(𝑋)=∫(−∞)(+∞)▒〖𝑥2 𝑓 (𝑥)𝑑𝑥〗−(𝔼(𝑋))^2\nStandard deviation : a real positive value, denoted 𝜎_𝑋 defined by : 𝜎_𝑋 = √(𝕍(𝑋) )\nCoefficient of variation : 𝐶𝑉 (𝑋) = 𝜎_𝑋/𝔼(𝑋) × 100\nCumulative distribution function : denoted by 𝐹_𝑋, defined on ℝ and with values in [0,1]. For all 𝑥 ∈ ℝ 𝐹_𝑋 (𝑥)=ℙ(𝑋 ≤𝑥)= ∫_(−∞)^𝑥▒〖𝑓 (𝑡)𝑑𝑡〗 Remarks The cumulative distribution function is increasing The cumulative distribution is a continuous function\nLinear transformation Let 𝑋 be a discrete random variable. Let 𝑎 and 𝑏 be two real values. We set 𝑌 = 𝑎𝑋+𝑏. We have : 𝔼 (𝑌 ) = 𝑎 (𝔼(𝑋)) + 𝑏. 𝕍 (𝑌 ) = 𝑎^2 (𝕍(𝑋)). If 𝑎 &gt; 0, then 𝜎(𝑌 ) = 𝑎𝜎(𝑋) If 𝑎 &lt; 0, then 𝜎(𝑌 ) = (−𝑎)𝜎(𝑋)\nStandard normal distribution\nOne can say that a random variable 𝑋 follows a standard normal distribution, denoted by 𝒩(0, 1), if its density is defined by :\n𝑓(𝑥)=1/√2𝜋 𝑒(−𝑥2/2)\nStandard normal distribution\n[[image normal distribution]] By definition, the total area equals 1\nStandard normal distribution\nShape of a bell. 𝑋(Ω)=ℝ, 𝔼(𝑋)=0 and 𝕍(𝑋) =1. For all 𝑥∈ℝ, we have 𝑓(𝑥)=𝑓(−𝑥) (𝑓 is even). Which implies that 𝑓 is a symetric function with respect to 𝑥 = 0.\n[[image normal distribution]] Remark 1 “Area” of the green part equals 1 - “Area” of the red part.\n[[image normal distribution]] Remark 2 Based on the symmetric property of 𝑓(𝑥), “Area” of the left part (in yellow) is equal to the “Area” of the right part (in red).\n[[image normal distribution]] Remark 3 “Area” of the blue part = “Area” of the grey part + “Area” of the blue part - “Area” of the grey part.\n“Area” of the green part in the first graph is equal to 𝐹_𝑋 (𝑢) =ℙ(𝑋 ≤ 𝑢) the cumulative distribution function of 𝑋 at 𝑢. “Area” of the yellow part in the second graph is equal to 𝐹_𝑋 (−𝑢)=ℙ(𝑋≤−𝑢) the cumulative distribution function of 𝑋 at −𝑢. “Area” of the red part in the second graph is equal to ℙ(X &gt; u). One can deduce that 𝐹_𝑋 (𝑢) = 1 − 𝐹_𝑋 (−𝑢). “Area” of the blue part in the third graph is equal to ℙ (𝑢 ≤ 𝑋 ≤ 𝑣) = 𝐹_𝑋 (𝑣) − 𝐹_𝑋 (𝑢) It is difficult to calculate the values 𝐹_𝑋 (𝑢)=ℙ(𝑋 ≤ 𝑢) for any 𝑢. Thoses values are provided by a table.\n[[tableau de la loi normale]] x2\nExamples : Let 𝑋 a random variable which follows a standard Normal distribution. Use the table to calculate : ℙ(𝑋 ≤ 2.12) = 0.983 ℙ(𝑋 ≤ −1.41) = 1 −ℙ(𝑋 ≤ 1.41) = 1 − 0.92073 ≃ 0.08 Search the table for values closest to 95%, 99%, 97.5% and 99.5% and give each time the value of 𝑢 that corresponds. Answers : 95% ← 𝑢 = 1.65 99% ← 𝑢 = 2.33 97.5% ← 𝑢 = 1.96 99.5% ← 𝑢 = 2.58\nNormal distribution Let 𝑚∈ℝ and 𝜎&gt;0. One can say that a random variable 𝑋 follows a normal distribution, denoted by 𝑋 ∼𝒩(𝑚, 𝜎), if its density is defined by :\n𝑓(𝑥)=1/(𝜎√2𝜋) 𝑒^(−1/2 ((𝑥−𝑚)/𝜎)^2 ) Shape of a bell. 𝑋(Ω)=ℝ, 𝔼(𝑋)=𝑚 and 𝕍(𝑋) = 𝜎^2. For 𝑚=0 and 𝜎=1, one can say that 𝑋 follows a standard Normal distribution. If 𝑋∼𝒩(𝑚, 𝜎), then 𝑌=(𝑋−𝑚)/𝜎 follows a standard Normal distribution.\nBinomial – Normal approximation : Let 𝑋 ~ℬ(𝑛, 𝑝). If 𝑛 is large (≥ 30) and 𝑝 is neither close to 0 nor to 1, such that 𝑛𝑝 &gt; 10 and 𝑛(1 − 𝑝) &gt; 10, then the binomial distribution can be approximated by a Normal distribution with parameters 𝑚 = 𝑛𝑝 and 𝜎 = √(𝑛𝑝(1 − 𝑝)) that is : ℙ(𝑎≤𝑋≤𝑏)≈ℙ(𝑎≤𝑌 ≤𝑏)=𝐹_𝑌 (𝑏)−𝐹_𝑌 (𝑎) and : ℙ(𝑋 = 𝑎) =ℙ(𝑋 ≤ 𝑎) −ℙ(𝑋 ≤ 𝑎 − 1) ≈ 𝐹_𝑌 (𝑎) − 𝐹_𝑌 (𝑎 − 1) where 𝐹_𝑌 is the cumulative distribution function of 𝑌 ~ 𝒩(𝑛𝑝,√(𝑛𝑝(1 − 𝑝))).\nPoisson – Normal approximation : Let 𝑋 ~ 𝒫𝑜(𝜆). If 𝜆 is large (&gt; 20), then the Poisson distribution can be approximated by a Normal distribution with parameters 𝑚 = 𝜆 and 𝜎 = √𝜆, that is : ℙ(𝑎≤𝑋≤𝑏)≈ℙ(𝑎≤𝑌 ≤𝑏)=𝐹_𝑌 (𝑏)−𝐹_𝑌 (𝑎) and : ℙ(𝑋 = 𝑎) =ℙ(𝑋 ≤ 𝑎) −ℙ(𝑋 ≤ 𝑎 − 1)≈ 𝐹_𝑌 (𝑎) − 𝐹_𝑌 (𝑎 − 1) where 𝐹_𝑌 is the cumulative distribution function 𝑌 ~𝒩(𝜆,√𝜆).\ndetailed examples Let 𝑋 ~ ℬ(100, 0.3) We have: ℙ (30 ≤ 𝑋 ≤ 40) = 0.4384 ℙ(𝑋 &gt; 40) =0.01250\nWhat are the estimates obtained for these probabilities using the Normal distribution approximation?\nSoit 𝑋 ~ ℬ(100, 0.3) : ℙ (30 ≤ 𝑋 ≤ 40) = 0.4384 Approximation by : 𝑌 ~𝒩(30, 4.583) ℙ (30 ≤ 𝑌 ≤ 40)= ℙ((30 −30)/4.583≤(𝑌 −30)/4.583≤ (40 −30)/4.583) = ℙ(0≤(𝑌 −30)/4.583≤2.182 )\n= 0.9855 − 0.5 = 0.4855\nℙ(𝑋 &gt; 40) =0.01250 Approximation by : 𝑌 ~ 𝒩(30, 4.583) ℙ(𝑌 &gt; 40)=1− ℙ(𝑌≤40)=1− ℙ((𝑌 −30)/4.583≤ (40 −30)/4.583) =1−ℙ((𝑌 −30)/4.583≤2.182 )\n=1−0.9855 =0.0145\napplocation exercice In 1955, Wechler proposed to measure the IQ (Intellectual Quotient) of adults with two scales for measuring verbal skills and non-verbal skills. The overall score of the person tested is compared with the distribution of scores obtained by a representative sample of the population of a given age, whose performances follow a Normal distribution with average 100 and standard deviation 15.\nWhat is the percentage of people whose IQ is less than 80 ? What is the probability of getting An IQ between 90 and 100 ? An IQ between 100 and 110 ? An IQ more than 110 ?\nAnswers : Let 𝑋 be the random variable associated with the performance. We know that 𝑋 ∼𝒩(100, 15). Therefore, 𝑌 = (𝑋 − 100)/15 follows a standard Normal distribution ℙ(𝑋 ≤ 80) =ℙ(𝑌 ≤ (80 − 100)/15) =ℙ(𝑌 ≤ −1.333) = 1 −ℙ(𝑌 ≤ 1.333) = 1 − 𝐹_𝑌 (1.333) = 1 − 0.9088 = 0.09121\nℙ(90≤𝑋 ≤100) =ℙ((90 − 100)/15≤𝑌 ≤ (100 − 100)/15) =ℙ(−0.6667 ≤ 𝑌 ≤ 0)=ℙ(𝑌 ≤ 0)− 𝑃(𝑌 ≤ −0.6667) = 〖𝐹_𝑌 (0)−(1−𝐹〗_𝑌 (0.6667))=0.5−(1−0.7475) = 0.2475 ℙ(100≤𝑋 ≤110) =ℙ((100 − 100)/15≤𝑌 ≤ (110 − 100)/15) = ℙ (0 ≤ 𝑌 ≤0.6667) =ℙ(𝑌 ≤0.6667)−ℙ(𝑌 ≤ 0) = 𝐹_𝑌 (0.6667)− 𝐹_𝑌 (0)= 0.7475 − 0.5 = 0.2475 \u000b ℙ(𝑋 ≥110) =ℙ(𝑌 ≥ (110 − 100)/15) =1−ℙ(𝑌 ≤ (110 − 100)/15) = 1 − 𝐹_𝑌 (0.6667)= 1 − 0.7475 =0.2525\n\nExercice with solution\nExercice 1\nAccording to a study conducted by an insurance company: the distance in km before having the first accident follows a normal distribution of average 35000 and standard deviation 5000.\nWhat is the percentage of drivers who have the first accident before 25000 km? What is the percentage of drivers who have the first accident between 25000 and 40000 km? What is the percentage of drivers who have the first accident beyond 45000 km? Calculate 𝑥, such that 𝑃 (𝑋 ≤ 𝑥) = 0.75.\nSolution\nLet 𝑋 be the random variable corresponding to the distance before the first crash. By assumption, we have 𝑋 ~ 𝑁 (35000, 5000) . We set 𝑌 = (𝑋 − 35000)/5000. Thanks to this change of variable, we obtain that 𝑌 follows a reduced centered normal law.   𝑃 (𝑋 ≤ 25000) = 1 − 𝑃 (𝑌 ≤ 2) = 0.02275 𝑃 (25000 ≤ 𝑋 ≤ 40000) = 𝑃 (𝑌 ≤ 1) − (1 − 𝑃 (𝑌 ≤ 2)) = 0.81859 𝑃 (𝑋 ≥ 45000) = 1 − 𝑃 (𝑌 ≤ 2) = 0.02275 We seek to calculate 𝑥 such that 𝑃 (𝑋 ≤ 𝑥) = 𝑃 (𝑌 ≤ (𝑥 − 35000)/5000) = 0.75 According to the table of the reduced centered normal law, it can be deduced that  :\n(𝑥 − 35000)/5000 = 0.68 → 𝑥 = 38400\nExercice 2\nThe results of an evaluation test (scored out of 250) have an average of 200. These results follow a normal distribution whose variance is unknown. We know that the proportion of candidates who obtained a mark between 160 and 240 is equal to 95.44%. Calculate the variance of the results.\nSolution\nLet 𝑋 be the random variable corresponding to the test results. By assumption, we have that 𝑋 ~ 𝑁 (200, 𝜎). Let’s set 𝑌 = (𝑋 − 200)/𝜎. Thanks to this change of variable, we obtain that 𝑌 follows a standard normal law. Moreover, we have : 𝑃 (160 ≤ 𝑋 ≤ 240) = 2 𝑃 (𝑌 ≤ 40/𝜎) − 1 = 0.9544\nThis implies that 𝑃 (𝑌 ≤ 40/𝜎) =0.9772.\nFrom the standard normal distribution table, we can deduce that\n40/𝜎 ≈ 2 ⟹ 𝜎 ≈ 20⟹ 𝜎^2 ≈400\nExercice 3\nMr. Smith is elected with 51.3% of the votes. A survey is carried out at the exit of the meeting room where an investigator questions 1000 people chosen at random. Let 𝑋 be the random variable: “number of people who voted for Mr. Smith among the 1000 people questioned”. Determine the law of 𝑋. Calculate 𝐸(𝑋) and 𝜎(𝑋) Using an approximation that will be justified, calculate the probabilities of the following events: 𝑃 (𝑋 ≤ 500) 𝑃 (500 ≤ 𝑋 ≤ 520)\nSolution\nLet 𝑋 be the random variable that represents the number of people who voted for Mr. Smith among the 1000 respondents (the number of successes among 1000 tries, with a probability of success 𝑝 = 0.513)\nBy definition, 𝑋 follows a binomial distribution with parameters 𝑛 = 1000 and 𝑝 = 0.513. Thus, we have\n𝐸(𝑋) = 𝑛 𝑝 =513 and 𝜎 (𝑋) = √(𝑉 (𝑋)) = √(𝑛 𝑝 (1 − 𝑝)) = 15.80604 ≈ 15.8\nThe conditions for approximation of the binomial law by a normal law (with parameters 𝑚=513 and 𝜎=15.8) are satisfied. Let Y ~ 𝑁 (𝑚, 𝜎). We set 𝑍 = (𝑋 − 𝑚)/𝜎. Thanks to this change of variable, we obtain that 𝑍 follows a standard normal law.\nSo we get:  𝑃 (𝑋 ≤ 500) ≈ 𝑃 (𝑌 ≤ 500) = 𝑃 (𝑍 ≤ −0.82) = 0.2061081 𝑃(500≤𝑋≤520)≈𝑃(500≤𝑌≤520) =𝑃(−0.82≤𝑍≤1.44)=0.46\nExercice 4\nWhat is the probability of getting 2 at least 1050 times in 6000 rolls of a (balanced) dice?\nSolution\nLet 𝑋 be the random variable representing the number of twos one gets, among the 6000 die rolls (the number of successes among 6000 tries, with a probability of success p = 1/6)   By definition, 𝑋 follows a binomial distribution with parameters 𝑛 = 6000 and p = 1/6. Thus, we have :   𝐸(𝑋) = 𝑛 𝑝 =1000 and 𝜎 (𝑋) = √(𝑉 (𝑋)) = √(𝑛 𝑝 (1 − 𝑝)) = 28.86751 ≈ 28.87   The conditions for approximation of the binomial distribution by a normal distribution (with parameters 𝑚 = 175 and 𝜎 = 12.87) are satisfied. Let Y ~ 𝑁 (𝑚, 𝜎) . We set 𝑍 = (𝑋 − 𝑚)/𝜎. Thanks to this change of variable, we obtain that 𝑍 follows a reduced centered normal law.\nTherefore :  𝑃 (𝑋 ≥ 1050) ≈ 𝑃 (𝑌 ≥ 1050) = 1 − 𝑃 (𝑍 ≤ 1.73) ≈ 0.04181514\n\n\nmoodle test\nQuestion 1\nLet the variable X follow the normal law 𝒩(100, 30)\nThe probability ℙ(𝑋 ≤150) is: 0.3522 0.5522 0.7522 0.9522\nFeedback: Use a change of variable to obtain a standard normal distribution. Then use the table of that law to determine the probability.\nQuestion 2\nLet the variable X follow the normal law 𝒩(150, 40)\nThe probability ℙ(𝑋≥160) is: 0.3013 0.4013 0.5013 0.6013\nFeedback: Use a change of variable to obtain a standard normal distribution. Then use the table of that law to determine the probability.\nQuestion 3\nLet the variable X follow the normal law 𝒩(50, 10)\nThe probability ℙ(𝑋 ≤40) is : 0.1587 0.2587 0.3587 0.4587\nFeedback: Use a change of variable to obtain a standard normal distribution. Then use the table of that law to determine the probability.\nQuestion 4\nLet the variable X follow the normal law 𝒩(350, 100)\nThe probability ℙ(𝑋≥400) is : 0.1085 0.2085 0.3085 0.4085\nFeedback: Use a change of variable to obtain a standard normal distribution. Then use the table of that law to determine the probability.\nQuestion 5\nLet the variable X follow the normal law 𝒩(500, 300)\nThe probability ℙ(300≤𝑋≤600) is : 0.3781 0.4781 0.5781 0.6781\nFeedback: Use a change of variable to obtain a standard normal distribution. Then use the table of that law to determine the probability.\nQuestion 6\nLet the variable X follow the binomial law 𝔅(625;0.2)\nThe approximation by a normal distribution is given by : 𝒩(100, 15) 𝒩(100, 10) 𝒩(125, 10) 𝒩(125, 15)\nFeedback: We check that the criteria of the approximation of the Binomial law 𝔅(625;0.2) by a normal distribution apply, then we use 𝑚=𝑛𝑝 and 𝜎 = √(𝑛𝑝(1 − 𝑝))\nQuestion 7\nLet the variable X follow the binomial law 𝒩(100;𝜎) such that ℙ(𝑋 ≤110)=0.6915\nThen 𝜎 is approximately : 10 20 30 40\nFeedback: Use a change of variable to obtain a standard normal distribution. Then use the table of that law to determine u corresponding to the probability. Deduce 𝜎 knowing that (110−100)/𝜎 ≈𝑢\nQuestion 8\nLet the variable X follow the binomial law 𝒩(100;𝜎) such that ℙ(𝑋 ≤120)=0.7475\nThen 𝜎 is approximately : 10 20 30 40\nFeedback: Use a change of variable to obtain a standard normal distribution. Then use the table of that law to determine u corresponding to the probability. Deduce 𝜎 knowing that (120−100)/𝜎 ≈𝑢",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Continuous random variable"
    ]
  },
  {
    "objectID": "ibs/syllabus-data-description.html",
    "href": "ibs/syllabus-data-description.html",
    "title": "Syllabus",
    "section": "",
    "text": "Guillaume Gilles (guillaume.gilles@essca.eu)\n\nCourse Description\n\n\nCourse Learning Outcomes, Objectives\n\n\nCourse Calendar\n\n\n\n\n\n\n\n\nDate\nTopic\nTextbook’s Chapters\n\n\n\n\n#1\nSets and Combinatorial Analysis\n\n\n\n#2\nCalculation of probabilities\n\n\n\n#3\nDiscrete random variable\n\n\n\n#4\nContinuous random variable\n\n\n\n#5\nLab on Excel\n\n\n\n#6\nReview of descriptive statistics\n\n\n\n#7\nEstimation\n\n\n\n#8\nHypothesis Testing - Test of conformity to a reference value\n\n\n\n#9\nHypothesis testing - Comparison test\n\n\n\n#10\nLab on Excel\n\n\n\n#11\nTest ANOVA\n\n\n\n#12\nChi-Square Test\n\n\n\n#13\nLinear correlation coefficient Test\n\n\n\n#14\nLab on Excel\n\n\n\n\n\n\nCourse Grades:\n\nMidterm Exam: MCQ for 35% of your grade\nFinal Exam: 65% of your grade\n\n\n\nCourse goals & objectives\n\n\nClass meetings\nThis class is taught for students PGE programm during the spring semester at Bordeaux\n\n\nRequired materials\n\n\nClass meetings\n\n\nExams\n\n\nWork load\nYou are expected to put in about 4-6 hours of work / week outside of class. Some of you will do well with less time than this, and some of you will need more"
  },
  {
    "objectID": "ibs/ch17-chi-square-test.html",
    "href": "ibs/ch17-chi-square-test.html",
    "title": "Chi-Square Test",
    "section": "",
    "text": "The following questions are to be answered:\nDoes the time spent on social networks depend on the user’s gender? Is the effect of the treatment independent of the dose administered? Is there a link between hair color and eye color? Is there a link between marital status and job type? Etc…\nThe Chi-square test is used to check the existence or not of a link between two characters in a given population:\nWhen both characteristics are qualitative When one characteristic is qualitative and the other is quantitative When both characteristics are quantitative but the values have been grouped (in classes)\nThe first characteristic, designated by X, can be a quantitative or qualitative characteristic, with categories (or classes) [generally resulting from a grouping of the values of a quantitative characteristic or the modalities of a non-quantitative characteristic]. We will thus have the classes A1; … ;Ap  X has p modalities\nThe second characteristic, designated by Y, can be a quantitative or qualitative characteristic, with categories (or classes) [generally resulting from a grouping of the values of a quantitative characteristic or the modalities of a non-quantitative characteristic]. We will thus have the classes B1; … ;Bq  Y has q modalities\nThe purpose of the Chi-square test is to test:\nH0 : X and Y are independent\n    against\nH1 : X and Y are dependent\nTo do this, we take a sample from the population considered. This sample of size n is represented by a contingency table of dimension p x q.\n\n1 Notations\n\nni,j represents the number of people who belong simultaneously to the category Ai of the dimension X and to the category Bj of the dimension Y\nni,. represents the sum of the numbers belonging to the category Ai of the dimension X\nn.,j represents the sum of the numbers belonging to the category Bi of the dimension Y\n\n2 The formulas to perform the test We need to calculate the following expression (called Computed Chi-square):\n\nOù\nThe test statistic uobs is therefore a comparison between the observed numbers and the theoretical numbers (Ei,j), i.e. the numbers under the hypothesis of independence.\nDecision rule : We reject H0 if uobs ≥ k, otherwise we do not reject H0  This implies: the rejection of the independence of the two characters X and Y\nwhere k is defined as follows F(k) = 1- α, with F is the distribution function of the Chi-square distribution with υ = (p – 1) x (q -1) degrees of freedom\nk is calculated from the Chi-square distribution.\nCondition of use : Ei,j ≥ 5 for all i = 1; …. ; p and j = 1; … ; q. Note : when the previous conditions are not verified, it is necessary to gather classes in order to obtain sufficiently large numbers.\nThe Chi-square distribution.\nwith\nα υ = (p – 1) x (q -1)\n\n3 Conclusion of the test\n\nAs a reminder, the test is written : H0 : X and Y are independent against H1 : X and Y are dependent\nH0 is rejected: the data confirm that the two variables are dependent  This implies that there is a link between the two variables\nH0 is not rejected: the data do not confirm that the two variables are dependent. In other words, the data do not confirm a link between the two variables at an α% risk.\nAn experimental anti-Covid treatment is administered at three different doses d1, d2, d3 to a group of subjects with Sars-Cov-2 virus. The experiment is done in double blind. The number of subjects cured and the number of subjects not cured is counted for each dose. The data are presented in the contingency table below:\nWe wish to test, with a 5% risk, if the effect of the treatment is dependent on the administered dose.\n\n1 Formulation of the test and notations H0 : independence of the “effect” and “dose” characteristics Against H1 : dependence of the “effect” and “dose” characteristics\n\nThe variable X is the “dose” character  So we have p =number of modalities of X = 3 The variable Y is the “effect” character  So we have q = number of modalities of Y = 2\n\n2 The formulas to perform the test Step 1 : Calculation of the theoretical numbers Ei,j In other words, Ei,j is equal to the product of the total of ith row by the total of the jth column, divided by the total number of individuals.\n\nExample : E1,1 = (𝑛(1,.)×𝑛(.,1) )/𝑛=(60×130 )/226=34,51\nRecall that all values of Ei,j must be ≥ 5, otherwise it is necessary to aggregate classes in order to obtain sufficient calculated numbers.\n\n2 The formulas to perform the test Step 2 : Calculation of uobs\n\n𝑢𝑜𝑏𝑠= ((30 −34,51)²)/34,51 + ((42 −44,29)²)/44,29+ ((58 −51,19)²)/51,19+ ((30 −25,49)²)/25,49 + ((35 −32,71)²)/32,71 + ((31 −37,81)²)/37,81\n𝑢𝑜𝑏𝑠 = 3,8\n\n3 Conclusion of the test\n\nWith a risk α = 5%, the H0 hypothesis is not rejected.\nIn other words, with a 5% risk, the data do not confirm a link between the effect of the treatment and the administered dose.\nIn the early 1970s, the association “Prévention Routière” wanted to encourage the French to wear seat belts. To do so, the association asked a polling institute to study the link between the nature of an injury following an accident and the wearing of a seat belt. A random sample of 10,779 drivers involved in an accident yielded the following results:\nCan we say with a 5% risk, that there is a link between seat belt use and the nature of the injury? In other words, is the seat belt effective?\n\n1 Formulation of the test and notations H0 : independence of the character “Nature of injuries” and the character “Belt Against H1 : dependence of the character”Nature of injuries” and the character “Belt\n\nThe variable X is the character “Nature of the injury”  So we have p = number of modalities of X = 3 The variable Y is the character “Seatbelt”  So we have q = number of modalities of Y = 2\n\n12 / exercices\nA marketing company selected a random sample of housewives (women under 50 years of age - the main shopper in the household) to study the link between the marital status of housewives and their weekly coffee consumption. The results of this study are given in the following table:\nCan we say, with a 5% risk, that there is a link between the level of coffee consumption and marital status among housewives?\n\nFormulation of the test and notations H0 : independence of the “Marital status” and “Coffee consumption” characteristics Against H1 : dependence of the “Marital status” and “Coffee consumption” characteristics\n\nThe variable X is the character “Marital status”  So we have p = number of modalities of X = 3 The variable Y is the “Coffee consumption” character  So we have q = number of modalities of Y = 4\n\nThe formulas to perform the test Step 1 : Calculation of the theoretical numbers Ei,j\n\nEi,j ≥ 5\n\nThe formulas to perform the test Step 2 : Calculation of uobs\n\n𝑢𝑜𝑏𝑠= ((652 −715,62)²)/715,62 + ….+ ((67 −57,96)²)/57,96 𝑢𝑜𝑏𝑠 = 67,78\nThe Chi-square distribution\nwith\nα = 5% = 0,05 υ = (p – 1) x (q -1) = (3-1) x (4-1) = 2 x 3 = 6\nSo we have k = 12,592\n\nConclusion of the test\n\nWith a risk α = 5%, the H0 hypothesis is rejected.\nIn other words, with a 5% risk, the data confirm that there is a link between coffee consumption level and marital status among housewives.\n\n\n12 / moodle\nAfter the general assembly, the students of the University U have decided to go on strike to protest against a new law. The management of the university believes that the support for this movement depends on the students’ fields of study. In order to verify the management’s claim, a random sample of 150 students (from the different streams) was selected. Thus, the investigator asked the selected students their opinions regarding the movement. The results of this study are given by the following table:\nIf we want to know if scientists are more favorable than literary people, what hypothesis test should we use?\nA test of conformity to a reference proportion  A comparison test between two proportions ANOVA Test Chi-square test\nAfter the general assembly, the students of the University U have decided to go on strike to protest against a new law. The management of the university believes that the support for this movement depends on the students’ fields of study. In order to verify the management’s claim, a random sample of 150 students (from the different streams) was selected. Thus, the investigator asked the selected students their opinions regarding the movement. The results of this study are given by the following table:\nCan we say, with a 5% risk, that there is a link between students’ opinions and their fields of study?\nWhat is the value of 𝐸_1,1? 19,24 24,44 31,68 41,68\nAfter the general assembly, the students of the University U have decided to go on strike to protest against a new law. The management of the university believes that the support for this movement depends on the students’ fields of study. In order to verify the management’s claim, a random sample of 150 students (from the different streams) was selected. Thus, the investigator asked the selected students their opinions regarding the movement. The results of this study are given by the following table:\nWhat is the condition to respect concerning the number under the hypothesis of independance : 𝐸(𝑖,𝑗)? 𝐸(𝑖,𝑗)≥0 𝐸(𝑖,𝑗)≥5 𝐸(𝑖,𝑗)≥10 𝐸_(𝑖,𝑗)≥30\nAfter the general assembly, the students of the University U have decided to go on strike to protest against a new law. The management of the university believes that the support for this movement depends on the students’ fields of study. In order to verify the management’s claim, a random sample of 150 students (from the different streams) was selected. Thus, the investigator asked the selected students their opinions regarding the movement. The results of this study are given by the following table:\nCan we say, with a 5% risk, that there is a link between students’ opinions and their fields of study?\nWhat is the value of 𝑢_𝑜𝑏𝑠 ? 19,24 17,45 27,45 34,32\nAfter the general assembly, the students of the University U have decided to go on strike to protest against a new law. The management of the university believes that the support for this movement depends on the students’ fields of study. In order to verify the management’s claim, a random sample of 150 students (from the different streams) was selected. Thus, the investigator asked the selected students their opinions regarding the movement. The results of this study are given by the following table:\nCan we say, with a 5% risk, that there is a link between students’ opinions and their fields of study?\nWhat is the number of modalities of X ? 1 2 3 5\nAfter the general assembly, the students of the University U have decided to go on strike to protest against a new law. The management of the university believes that the support for this movement depends on the students’ fields of study. In order to verify the management’s claim, a random sample of 150 students (from the different streams) was selected. Thus, the investigator asked the selected students their opinions regarding the movement. The results of this study are given by the following table:\nCan we say, with a 5% risk, that there is a link between students’ opinions and their fields of study?\nWhat is the number of modalities of Y ? 1 2 3 5\nAfter the general assembly, the students of the University U have decided to go on strike to protest against a new law. The management of the university believes that the support for this movement depends on the students’ fields of study. In order to verify the management’s claim, a random sample of 150 students (from the different streams) was selected. Thus, the investigator asked the selected students their opinions regarding the movement. The results of this study are given by the following table:\nCan we say, with a 5% risk, that there is a link between students’ opinions and their fields of study?\nTo solve this kind of test, what table do we need to use ? The Normal Distribution table The Fisher Distribution Table The Chi-square table\nAfter the general assembly, the students of the University U have decided to go on strike to protest against a new law. The management of the university believes that the support for this movement depends on the students’ fields of study. In order to verify the management’s claim, a random sample of 150 students (from the different streams) was selected. Thus, the investigator asked the selected students their opinions regarding the movement. The results of this study are given by the following table:\nCan we say, with a 5% risk, that there is a link between students’ opinions and their fields of study?\nWhat is the value of k ? 3,841 5,991 9,448 12,592\nAfter the general assembly, the students of the University U have decided to go on strike to protest against a new law. The management of the university believes that the support for this movement depends on the students’ fields of study. In order to verify the management’s claim, a random sample of 150 students (from the different streams) was selected. Thus, the investigator asked the selected students their opinions regarding the movement. The results of this study are given by the following table:\nCan we say, with a 5% risk, that there is a link between students’ opinions and their fields of study?\nThe data confirm a link between students’ opinions and their fields of study The data do not confirm a link between students’ opinions and their fields of study",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Chi-Square Test"
    ]
  },
  {
    "objectID": "ibs/ch16-anova.html",
    "href": "ibs/ch16-anova.html",
    "title": "ANOVA",
    "section": "",
    "text": "This test is used to study the link between a quantitative variable and a qualitative variable.\nIn the previous example: the quantitative variable: sales the qualitative variable: the Merchandising display system (with four modalities) In other words, it means we need to examinate the null hypothesis: the means (of sales) of the four subpopulations (under each system) are identical.\nThe number of comparisons increases geometrically. In our example, there are four Merchandising Display Systems, which means that we have six comparisons to make. If we consider an additional system, we will have ten comparisons to make, etc…\nInflation of the number of tests  increases the risk α. Back to our example, we set α = 5%. For each comparison, we have a probability of 1 - α = 95% of accepting the hypothesis. So a probability of (0.95)6 of accepting it 6 times. Which means a probability of 1 - (0.95)6 ≅ 0.27 of rejecting it at least once. Advantages of the ANOVA Test (ANalysis Of VAriance) : One test is enough With a risk (5% for example) we can test the difference between the means\nThe limitation of the ANOVA Test: We don’t know which averages are different\n    The \"theoretical\" conditions of application of ANOVA will not be discussed in this course\nLet:\n\nk : the number of distinct groups (which corresponds to the number of modalities of the qualitative variable) and mj : the mean of the quantitative variable knowing the modality j of the qualitative variable (this is a conditional mean) In other words, mj is the unknown theoretical mean of the quantitative variable of the jth group\n\nThe purpose of the ANOVA test is to test:\nH0 : m1 = m2 = …. = mk\n    against\nH1 : At least 2 different means\n\n1 Notations\n\nk = number of groups nj = number of elements in the jth group n = the total number of elements xi,j = the value measured for the ith element of the jth group. i varies from 1 to nj and j varies from 1 to k The average of the jth group :\nThe total average :\n\n2 The formulas to perform the test The interclass Average Square (A.S.inter) :\n\nThe intraclass Average Square (A.S.intra)\n\n3 Calculation of Uobs\n\nDecision rule: We reject H0 if uobs ≥ f, otherwise we do not reject H0\nwhere f is defined as follows F(f) = 1- α, with F is the distribution function of the Fisher distribution with v1 = k - 1 and v2 = n - k degrees of freedom\nf is calculated from the Fisher Distribution. Note that for each fixed α, there is a specific table. In this course, we have the table of the Fisher distribution for α = 5%\nThe Table of the Fisher Distribution for α = 5%.\nv1 = k – 1 v2 = n – k\n\n4 Conclusion of the test\n\nH0 rejected: the data confirm that all means are not equal (that there is at least one different mean)  This implies that there is a link between the two criteria studied\nH0 not rejected: the data do not confirm that all means are not equal (we can not confirm that there is at least one different average from the others)\n3.1 Notations\nk = number of groups = (A1, A2, A3 et A4) = 4 n1 = number of elements in group A1 = 5 n2 = number of elements in group A2 = 5 n3 = number of elements in group A3 = 5 n4 = number of elements in group A4 = 5 n = total number of éléments = n1 + n2 + n3 + n4 = 5 + 5 +5 +5 = 20 (𝑥_1 ) ̅=(120+118+122+110+130)/5=120 is the average sales for A1 (Shelf end) (𝑥_2 ) ̅=(122+120+132+124+112)/5=122 is the average sales for A2 (Lower Shelf end) (𝑥_3 ) ̅=(116+108+116+116+124)/5=116 is the average sales for A3 (Upper floor) (𝑥_4 ) ̅=(122+114+122+122+130)/5=122 is the average sales for A4 (Lower floor) 𝑥 ̿=(120+118+…+122+130)/20=120 is the average total sales\n\n3 Calculation of Uobs\n\nAccording to the Fisher Distribution table with α = 5%. v1 = k – 1 = 4 – 1 = 3 v2 = n – k = 20 – 4 = 16\n                            So we have\n\n4 Conclusion of the test\n\nWith a risk α = 5%, the hypothesis H0 is not rejected In other words, the data do not confirm that the average sales under the four Merchandising Display Systems are different. In other words, the data does not confirm that the 4 Merchandising Dislpay systems (Gondola, lower gondola, eye level and stoop level) has an effect on sales.\nThe following table presents measurements of the height (in mm) of a plant (a fern), made in several different environments in France, on randomly sampled samples. A researcher wants to compare these data to find out the effect of environment on plant size.\nCan we say, with a 5% risk, that the environment has an influence on the size of the fern?\nLet 5 be the number of distinct environments: Env 1 : Mediterranean Coast Env 2 : The Alps Env 3 : Hautes-De-France Env 4 : South Atlantic coast Env 5 : Brittany\nThe ANOVA test is written as follows:\nH0 : m1 = m2 = m3  = m4\n    against\nH1 : At least 2 different means\n4.1 Notations\nk = number of groups = (Env 1, Env 2, Env 3, Env 4 and Env 5) = 5 n1 = number of measurements in Env1 = 8 n2 = number of measurements in Env2 = 5 n3 = number of measurements in Env3 = 6 n4 = number of measurements in Env4 = 5 n5 = number of measurements in Env5 = 7 n = the total number of measures = n1 + n2 + n3 + n4 + n5 = 8 + 5 + 6 + 5 + 7 = 31\n(𝑥_1 ) ̅=(112+115+112+118+124+132+131+115)/8=119,875 is the average height of the plant in Env1 (𝑥_2 ) ̅=(141+146+135+147+154)/5=144,6 is the average height of the plant in Env2 (𝑥_3 ) ̅=(156+167+143+178+145+169)/6=159,67 is the average height of the plant in Env3 (𝑥_4 ) ̅=(187+105+179+123+114)/5=141,6 is the average height of the plant in Env4 (𝑥_5 ) ̅=(241+264+225+257+248+258+136)/7=232,71 is the average height of the plant in Env5 𝑥 ̿=(112+115+…+258+136)/31=160,55 is the total average height of the plant (whatever the environment)\n\n11 / exercices\nA data analyst at a business school (in France) is trying to determine whether the academic performance of first-year students is a function of their type of bachelor’s degrees (Bac ES, Bac S or Bac STG). To do that, he observes the performance of 18 first-year students, 7 of whom come from a Bac ES, 6 from a Bac S and 5 from a Bac STG. Performance is measured by the average of all the subjects taken by the students:\nCan we say, with a 5% risk, that the types of bachelor’s degrees do not have the same effects on the academic performance of first-year students?\nLet 3 be the number of groups: (There are 3 different BAC) Bac 1 : ES Bac 2 : S Bac 3 : STG\nThe ANOVA test is written as follows:\nH0 : m1 = m2 = m3  = m4\n    against\nH1 : At least 2 different means\n\nNotations\n\nk = number of groups = (Bac ES, Bac S, Bac STG) = 3 n1 = number of students coming from a Bac ES = 7 n2 = number of students coming from a Bac S = 6 n3 = number of students coming from a Bac STG = 5 n = the total number of students = n1 + n2 + n3 = 7 + 6 + 5 = 18\n(𝑥_1 ) ̅=(77+68+96+82+84+75+100)/7=83,14 is the average performance of 1st year students from a Bac ES (𝑥_2 ) ̅=(85+71+91+93+100+85)/6=87,5 is the average performance of 1st year students from a Bac S (𝑥_3 ) ̅=(60+6575+75+80)/5=71 is the average performance of 1st year students from a Bac STG 𝑥 ̿=(77+68+…+75+80)/18=81,22 is the total average of the students’ 1st year performance (regardless of their BAC)\n\nConclusion of the test\n\nWith a risk α = 5%, the hypothesis H0 is rejected\nIn other words, the data confirm that there is at least one different average.\nIn other words, the data allow us to confirm with a 5% error that the type of bachelor’s degrees has an influence on the academic performance of first-year students.\n\n\n11 / moodle\nThe maximum daily wind speed was measured (during the same period of the year) at three synoptic stations: A, B and C. These are based in different geographical areas. The results of the survey give us the following results:\nCan we say, with a 5% risk, that the geographical areas of the stations do not have the same effects on the maximum daily wind speed?\nTo answer this question, what hypothesis test should be performed? A test of conformity to a reference average  A comparison test between two means ANOVA Test\nThe maximum daily wind speed was measured (during the same period of the year) at three synoptic stations: A, B and C. These are based in different geographical areas. The results of the survey give us the following results:\nWhat is the sum of the interclass mean squares (〖𝑆𝑆𝐷〗_𝑖𝑛𝑡𝑒𝑟) ? 16,59 26,62 36,59 46,59\nThe maximum daily wind speed was measured (during the same period of the year) at three synoptic stations: A, B and C. These are based in different geographical areas. The results of the survey give us the following results:\nThe maximum daily wind speed was measured (during the same period of the year) at three synoptic stations: A, B and C. These are based in different geographical areas. The results of the survey give us the following results:\nWhat is the value of the sum of squares of the intraclass deviations (〖𝑆𝑆𝐷〗_𝑖𝑛𝑡𝑟𝑎) ? 212,36 222,36 232,36 242,35\nThe maximum daily wind speed was measured (during the same period of the year) at three synoptic stations: A, B and C. These are based in different geographical areas. The results of the survey give us the following results:\nWhat is the value of the intraclass average square (A〖.𝑆〗_𝑖𝑛𝑡𝑟𝑎) ? 12,16 14,26 16,16 18,26\nThe maximum daily wind speed was measured (during the same period of the year) at three synoptic stations: A, B and C. These are based in different geographical areas. The results of the survey give us the following results:\nWhat is the value of 𝑢_𝑜𝑏𝑠 ? 0,65 0,75 0,82 0,92\nThe maximum daily wind speed was measured (during the same period of the year) at three synoptic stations: A, B and C. These are based in different geographical areas. The results of the survey give us the following results:\nThe maximum daily wind speed was measured (during the same period of the year) at three synoptic stations: A, B and C. These are based in different geographical areas. The results of the survey give us the following results:",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "ANOVA"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello, welcome on my website!",
    "section": "",
    "text": "Nice to meet you and welcome to my website, a corner of the Internet where I cultivate my digital garden."
  },
  {
    "objectID": "ibs/ch13-estimation.html",
    "href": "ibs/ch13-estimation.html",
    "title": "Estimation",
    "section": "",
    "text": "Graphical representation of the Normal Distribution N(0;1\nLet u be a real &gt; 0 (unknown) and α a fixed probability. Assume that X follows N(0; 1). Let us denote 𝐹_𝑋 the distribution function of X. We are looking for u, such as 𝑃(|𝑋| ≤𝑢)=𝑃(−𝑢 ≤𝑋 ≤𝑢)=1 − 𝛼\n𝑃(−𝑢 ≤𝑋 ≤𝑢)= 2 𝑃(𝑋 ≤𝑢)−1\nIt implies 𝐹𝑋 (𝑢)=𝑃(𝑋 ≤𝑢)=1 − 𝛼/2 So we have 𝑢= 𝐹𝑋^(−1) (1 − 𝛼/2)\nExample :\nLet X follow N(0; 1). We look for the unknown real 𝑢 &gt; 0, such that 𝑃(−𝑢 ≤𝑋 ≤𝑢)=0.95=1 −0.05 So we have,\n𝑢= 𝐹𝑋^(−1) (1 − 0.05/2) = 𝐹𝑋^(−1) (0.975)\nUsing the table of the centered reduced normal distribution in an “inverted” way, we can deduce that\n𝑢=1.96\nModeling framework\nProblem 1:\nThe quality department of a factory, noted U, is interested in the average life of an electronic circuit, noted CE110, manufactured and marketed by the factory U.\nModeling framework : From the problem, we must be able to identify :\nThe population : The variable studied :\nProblem 1:\nThe quality department of a factory, noted U, is interested in the average life of an electronic circuit, noted CE110, manufactured and marketed by the factory U.\nModeling framework : From the problem, we must be able to identify :\nThe population : CE110 circuits The variable studied : lifetime\nTo go further, we need a probabilistic framework\n\nModeling assumption : the variable studied, noted X, follows a “𝔏” distribution\n\nIn other words, the variable studied on the population is a random variable (whose events are “controlled” by the distribution “𝔏”)\nProblem 1:\nModeling framework : From the problem, we must be able to identify :\nThe population : CE110 circuits The variable studied : lifetime\n\nModeling assumption : the variable studied, noted X, follows a “𝔏” distribution\n\nBut this distribution “𝔏” is generally :\nTotally unknown: we have no information Partially unknown: we know to which family (of distributions) it belongs but we do not have its associated parameters\nHowever, this lack of information about the “𝔏” distribution is not central to the problem we are dealing with  here, we are interested in the average life\nProblem 1:\nThe quality department of a factory, noted U, is interested in the average life of an electronic circuit, noted CE110, manufactured and marketed by the factory U.\nModeling framework :\nThe population : CE110 circuits The variable studied : lifetime\n\nModeling assumption : the variable studied, noted X, follows a “𝔏” distribution Unknown parameter(s) : 𝑚=𝔼(𝑋)\n\nProblem 2:\nThe quality department of a factory, noted U, is interested in the rate of defective parts produced by the machine M during the manufacturing of an electronic circuit, noted CE110.\nModeling framework :\nThe population : The variable studied : Modeling assumption : Unknown parameter(s) :\nProblem 2:\nThe quality department of a factory, noted U, is interested in the rate of defective parts produced by the machine M during the manufacturing of an electronic circuit, noted CE110.\nModeling framework :\nThe population The CE110 circuits manufactured by the M\n\nThe variable studied : 𝑋 (Ω)= {1 (𝑑𝑒𝑓𝑒𝑐𝑡𝑖𝑣𝑒) ; 0 (𝑛𝑜𝑡 𝑑𝑒𝑓𝑒𝑐𝑡𝑖𝑣𝑒)} Modeling assumption : The studied variable, noted X, follows a Bernoulli distribution of parameter 𝑝=ℙ(𝑋 = 1) Unknown parameter(s) : 𝑝\n\nInfer (definition):\nDraw a conclusion from a fact or proposition\nIn philosophy:\nOperation by which one passes from a set of premises (hypotheses) to a justified conclusion, made legitimate by these premises\nDefinition (academic):\nA set of methods makes it possible to formulate (in probabilistic terms) a “judgment” on the characteristics of a population from the results observed on a part of the population.\nExtension:\nA set of “tools” that allow to generalize from a particular case\nIt is obvious that this passage will / can generate errors (of judgment) In other words, a risk of being wrong\nModeling framework reminder:\nThe population The studied variable : X Modeling assumption : the variable studied, noted X, follows a “𝔏” distribution\nSample (theoretical definition) :\n𝑋1, 𝑋_2, …, 𝑋𝑛 n independent (two by two) and identically distributed variables (having the same distribution “𝔏”)\nData set (the empirical or observed sample):\n𝑥1, 𝑥_2, …, 𝑥𝑛 the realizations of the theoretical sample\nData Vs. Dataset:\nWhen we use the term “data” we assume that a priori there is no “probabilistic hypothesis” concerning the observed values.\nWhen we use the term “data set” we assume that a priori there is a “probabilistic hypothesis” concerning the observed values. In other words, the observed values are realizations (in relation to the characteristic under study) of a sequence of random experiments.\nLet 𝑞 be the unknown parameter\n𝑄 an estimator of 𝑞 is a function of the theoretical sample (i.e., a function of variables 𝑋1, 𝑋_2, …, 𝑋𝑛)  it is a random variable 𝑄=ℎ(𝑋1, 𝑋_2, …, 𝑋𝑛)\n𝑞 ̂ estimate of 𝑞 is the image of the associated estimator, via the data set\n𝑞 ̂ =ℎ(𝑥1, 𝑥_2, …, 𝑥𝑛)\n\n07/exercice\nQuestion 1\nModeling framework :\nThe population : the days (of activity of the service department) The studied variable : the number of calls received between 12pm and 2pm Modeling assumption : the variable studied, noted X, follows a “𝔏” distribution Unknown parameter(s) : 𝑚=𝔼(𝑋) and 𝜎= 𝜎(𝑋)\nEmpirical results:\nThe empirical mean (estimate of m) : 𝑥 ̅ = 3.23 The empirical standard deviation (estimate of σ) : s = 2.366213 The size of the data set : n = 200 (&gt; 30)\nQuestion 2\nModeling framework :\nThe population : the days (of activity of the service department) The studied variable : 𝑋 (Ω)= {1 (𝑛𝑏 𝑜𝑓 𝑐𝑎𝑙𝑙𝑠≥6) ; 0 (𝑛𝑏 𝑜𝑓 𝑐𝑎𝑙𝑙𝑠&lt;6)} Modeling assumption : The variable studied, denoted X, follows a Bernoulli distribution of parameter 𝑝 = ℙ(𝑋 = 1) Unknown parameter(s) : 𝑝\nEmpirical results:\nThe size of the data set : n = 200 (&gt; 30) k (number of favorable cases)= 23 + 7 The estimate of p is given by 𝑝 ̂ = (23 +7)/200 = 0.15\nQuestion 1 :\nCompute the confidence interval of the average amount paid (in taxes) by taxpayers for a risk α set at 7%, 5% and 1%. Comment.\nQuestion 2 :\nLet p be the rate of taxpayers who pay less than 1400. Compute the confidence interval of p for a risk α set at 10%, 4%, and 1%. Comment.\nQuestion 1\nModeling framework :\nThe population : taxpayers The studied variable : the amount of taxes (to be paid) Modeling assumption : the variable studied, noted X, follows a “𝔏” distribution Unknown parameter(s) : 𝑚=𝔼(𝑋) and 𝜎= 𝜎(𝑋)\nEmpirical results:\nThe empirical mean (estimate of m) : 𝑥 ̅ = 1461 The empirical standard deviation (estimate of σ) : s ≈ 373.0464 The size of the data set : n = 300 (&gt; 30)\nQuestion 2 : Modeling framework :\nThe population : taxpayers The studied variable :𝑋 (Ω)= {1 (𝑡𝑎𝑥 𝑎𝑚𝑜𝑢𝑛𝑡&lt;1400) ; 0 (𝑡𝑎𝑥 𝑎𝑚𝑜𝑢𝑛𝑡≥1400)} Modeling assumption : The variable studied, denoted X, follows a Bernoulli distribution of parameter 𝑝 = ℙ(𝑋 = 1) Unknown parameter(s) : 𝑝\nEmpirical results: The size of the data set : n = 300 (&gt; 30) k (number of favorable cases) = 12 + 30 + 90 The estimate of p is given by 𝑝 ̂ = (12 + 30 +90)/300 = 0.44\n\n\n07/moodle\nExercise 1 :\nA store manager wants to study the average amount spent by his customers. To do this, he selected (at random) 40 customers and measured the amount spent by them. Please find below the results of this study:\n30.18 33.29 30.86 26.86 36.52 31.61 28.07 32.61 28.31 30.21 31.72 32.45 31.34 31.19 35.12 29.99 32.55 30.12 30.85 29.52 31.06 33.29 35.15 29.17 32.01 32.42 31.82 33.86 32.25 29.87 32.24 28.98 31.25 30.24 27.92 32.01 28.74 28.24 32.51 28.21\nThus, we can deduce that:\nThe 40 clients represent the study population A. True B. False\nFeedback : the population is not composed of 40 clients.\nThe average expenditure of the store’s customers is equal to 31.11525 A. True B. False\nFeedback : 31.11525 is the empirical mean\n\n2.086953 is an estimate of the standard deviation of the amount spent by store customers A. True B. False\nFeedback : check the calculations using the formula for calculating the variance when the data are represented in their raw state.\nThe probability that the average amount spent by customers in the store is between 30.4685 and 31.762, is equal to 95%. A. True B. False\nFeedback : check the calculations using the formula for calculating the confidence interval of a mean with a confidence level of 95%.\n\nExercise 2\nThe manager of a shopping mall is interested in the rate of visitors buying from the mall. To do so, he asked the following question: “Did you buy something during your visit?” to 70 (randomly selected) visitors of the mall. The results of this study are presented below:\n0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 Positive answer = 1 Negative answer = 0 Thus, we can deduce that:\n47.14% is an estimate of the mall’s shopper rate. A. True B. False\nFeedback : the empirical proportion is equal to the number of favorable cases divided by the number of possible cases.\n\nThe probability that the rate of shopping center visitors is between 38.85% and 51.64% is equal to 95%. A. True B. False\nFeedback : check the calculations using the formula for calculating the confidence interval of a proportion with a 95% confidence level.",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Estimation"
    ]
  },
  {
    "objectID": "ibs/ch12-review-descriptive-stat.html",
    "href": "ibs/ch12-review-descriptive-stat.html",
    "title": "Review of descriptive statistics",
    "section": "",
    "text": "Univariate data\nBivariate data\nThe objective of this session is to perform a reminder of some numerical summaries associated with describing the data. These numerical summaries were covered during the “data description” course (first year, semester 2)Mastering these calculations is essential for the rest of the course.Note that in this session we do not impose any “probabilistic hypothesis” on the data. In other words, we are only interested in the description of the data through the numerical summaries without taking into account the existence of a probability law related to these data.\nIndividual (an element of the population Population: a set of elements sharing one or more characteristics that serve to group them together Population is said to be finite if we can determine the exact number of its individuals (otherwise it is said to be infinite)\nVariable qualitative nominal ordinal quantitative discrete continuous\nA population is finite if the number of its individuals is finite. A population is infinite if we cannot determine the “exact” number of its individuals.\nHair color of hair salon customers  The answers are unordered qualities (It’s a qualitative nominal variable)\nThe level of customer satisfaction of a telephone operator  The answers (very dissatisfied / dissatisfied / satisfied / very satisfied) are qualities with a logical order (It’s an ordinal qualitative variable)\nThe number of people in Parisian households  the answers are numbers, and the set of answers is finite or countable (It’s a discrete quantitative variable)\nThe “exact” waiting time on the phone of customers before being answered by the technical service of an internet provider  the answers can be “any values” in an interval (It’s a continuous quantitative variable)\nIn this session, we will focus only on quantitative / measurable variables.\nAlso, note that unlike the first part of the course, we did not associate the adjective “random” with the term “variable”.\nIndeed, as mentioned in the foreword of the session, we are only interested in describing the data without imposing any “probabilistic framework”.\nUnivariate data = Statistical series A sequence of observations of a variable studied for all individuals in a population or a part of the population\nTotal number of observations = n Number of individuals involved in the study\nThe data is usually collected in its raw state (without any particular organization / as a column in an Excel file), i.e. in the following form : 𝑥1, 𝑥_2, …, 𝑥𝑛 Where 𝑥_𝑖 is the “answer” of the i-th individual\nA modality is a category of answers obtained/observed\nCalculation of the mean\ncalculation of the variance\nstandard deviation\ncoefficient ofvariation",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Review of descriptive statistics"
    ]
  },
  {
    "objectID": "ibs/ch12-review-descriptive-stat.html#reminder-data-desc-exercices",
    "href": "ibs/ch12-review-descriptive-stat.html#reminder-data-desc-exercices",
    "title": "Review of descriptive statistics",
    "section": "06 / reminder data desc / exercices",
    "text": "06 / reminder data desc / exercices\n𝑥 ̅= (−1×40+0×34+2 ×86+3 ×20+7×20)/200 =−1 ×0.2+0×0.17+2×0.43+3×0.1+7×0.1 =1.66\n𝑠= √((〖(−1)〗2×40+02×34+22×86+32×20+ 7^2×20)/200 − (1.66” ” )^2 )\n= √(〖((−1)〗2×0.2+02×0.17+22×0.43+32×0.1+ 7^2×0.1) −(1.66” ” )^2 )\n=2.228093\nC.𝑉.(𝑥)= 𝑠/𝑥 ̅ ×100=134.2225 %&gt;15%\n𝑥 ̅= (5×42+20×48+50×90+85×24+125×36)/240=50.875\n𝑠= √((52×42+〖20〗2×48+〖50〗2×90+〖85〗2×24+ 〖125〗^2×36)/240 − (50.875” ” )^2 )\n= √(〖(5〗2×0.175+〖20〗2×0.2+〖50〗2×0.375+〖85〗2×0.1+ 〖125〗^2×0.15) −(50.875)^2 )\n=38.72802\n𝑐.𝑣(𝑥)= 𝑠/𝑥 ̅ ×100=76.12387 %&gt;15",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Review of descriptive statistics"
    ]
  },
  {
    "objectID": "ibs/ch12-review-descriptive-stat.html#reminder-data-desc-moodle",
    "href": "ibs/ch12-review-descriptive-stat.html#reminder-data-desc-moodle",
    "title": "Review of descriptive statistics",
    "section": "06 / reminder data desc / moodle",
    "text": "06 / reminder data desc / moodle\nExercise 1 :\nThe data below represent the scores (in math) obtained by n candidates in an entrance exam (for a management school) 8 15 11 12 7 10 16 18 9 11 3 13 14 17 7 8 12 13 16 15 9 15 7 11 9 14 17 8 12 8\nWe can deduce :\nThe number of candidates studied is equal to 29 A. True B. False\nFeedback : recount again!!!\nThe average score (in math) of the candidates studied is equal to 11. A. True B. False\nFeedback : check the calculations using the formula for calculating the average when the data is represented in its raw state.\n\nThe standard deviation of the observed scores is approximately equal to 3.6583 A. True B. False\nFeedback : check the calculations using the formula for calculating the variance when the data is represented in its raw state.\nLes notes des candidats étudiés tournent autour de la moyenne des notes. A. True B. False\nFeedback : check the calculations of the mean and standard deviation in order to correctly interpret the coefficient of variation.\n\nThe table below represents the age distribution of 𝑛 (number not reported) voters in the last municipal election of a French city, denoted V.\nWe can deduce that :\nThe center of the last class is equal to 73.5 years A. True B. False\nFeedback : by convention, the last class has the same width as the class [35, 60[.\n\nThe center of the first class is equal 19 years A. True B. False\nFeedback : a voter must “by definition” be of age (in France) !!!\nThe average age of 𝑛 voters in the last municipal election in City V is equal to 46.325 years.\n  A. True\n  B. False\nFeedback : check the calculations using the formula for calculating the mean when the data are from a continuous variable and represented in a table. Remember that frequencies are defined by :\n\n𝑓𝑖= 𝑛𝑖/𝑛 4. The standard deviation of the age of 𝑛 voters in the last municipal election in city V is equal to 21.07681 years. A. True B. False\nFeedback : check the calculations using the formula for calculating the variance when the data are from a continuous variable and represented in a table. Remember that frequencies are defined by :\n𝑓𝑖= 𝑛𝑖/𝑛",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Review of descriptive statistics"
    ]
  },
  {
    "objectID": "ibs/part2-decision-making-statistics.html",
    "href": "ibs/part2-decision-making-statistics.html",
    "title": "Decision Making Statistics",
    "section": "",
    "text": "Decision Making Statistics",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Decision Making Statistics"
    ]
  },
  {
    "objectID": "ibs/ch14-hypothesis-testing.html",
    "href": "ibs/ch14-hypothesis-testing.html",
    "title": "Hypothesis Testing - Test of conformity to a reference value",
    "section": "",
    "text": "Assertion :\nIn logic, an assertion is a sentence to which we can assign a truth value (true or false). In other words, an assertion can be either true or false (but never both)\nExamples :\n“18 is divisible by 9” is a true statement “π is an integer” is a false statement\nNegation of an assertion :\nIf an assertion is true, its negation is false If an assertion is false, its negation is true\nExamples :\nP: “1000 is less than or equal to 500“ no(P):”1000 is strictly greater than 500 P : « 2^2=4 »  no(P) : « 2^2≠4 »\nDefense strategy (attorney):\nThe goal is to show that her client is innocent/not guilty\nShe starts by assuming that her client is guilty!!!\nBut guilt implies certain characteristics or evidence: She seeks to find a contradiction\nPresumption of innocence:\n“Any person suspected or prosecuted is presumed innocent until proven guilty.” “The accused is presumed innocent and that doubt must benefit him”. “Everyone has the right to respect for the presumption of innocence.” The trial consists of gathering and presenting evidence to invalidate the “not guilty” of the accused\nAccept the error!!!\nA coin is tossed 10 times in a row and lands on its head 10 times in a row\nThis seems to be very strong evidence to conclude that the piece is biased\nThere is almost one chance in a thousand that this will happen even if the if the room is balanced\nWhen making decisions, the goal is not to eliminate errors, but to minimize them.\nLogical conclusion\nThe rejection of guilt implies the non-guilt of the defendant\nThe non-rejection of guilt implies that we do not have elements that allow us to confirm the non-guilt of the accused\nIt does not confirm guilt\n[…]\nThe quality manager of a factory confirms that during the year 2019, the average daily number of defective parts is equal to 4.\nThe quality manager has asked (at the beginning of 2020) a team of specialized technicians to intervene in order to make some adjustments to the parameters of the production machines.\nThe quality manager is now wondering if, following the intervention of the team of technicians, the current situation :\nHas evolved / changed became worse (i.e., the intervention was not beneficial) Has improved (i.e., the intervention was beneficial)\nTo answer the quality manager’s questions, simply compare the current average daily number of defective parts with 4\nTransforming the problem into a modeling framework:\nPopulation : the days (of activity of the plant) after the intervention of the technicians\nStudied variable : the number of defective parts\nModeling assumption : the variable studied, noted 𝑋, follows a probability distribution “𝔏”\nUnknown parameter(s) : 𝑚=𝔼(𝑋) and 𝜎= 𝜎(𝑋)\nReference information : a reference average 𝑚_0=4\nThe quality manager’s questions can be translated as follows:\nThe current situation has changed  𝒎 ≠𝒎𝟎=𝟒 The current situation has become worse  𝒎&gt;𝒎𝟎=𝟒 The current situation has improved  𝒎&lt;𝒎_𝟎=𝟒\n[…]\nApproach 1:\nIf we have perfect knowledge of the distribution “𝔏”, then the problem becomes purely “probabilistic”\nSimply calculate 𝑚=𝔼(𝑋) and compare this to the reference mean 𝑚_0\nApproach 2:\nWe can proceed by census: in other words, study the unknown parameter(s) on the whole population\nApproach 3:\nWe can proceed by sampling: in other words, study the unknown parameter(s) on a part of the population\nRemark :\nGiven that perfect knowledge of the “𝕷” distribution is rather utopian. The sampling procedure is often preferred for processing\nThis procedure allows to bypass a number of difficulties / disadvantages of the census procedure:\nAccessibility to the entire population The cost The time …\nThe “reliability” of this procedure obviously depends on the “selection quality” of the individuals and the number of individuals.\nThus, we proceed by sampling. We therefore have a “data set” associated with the variable under study, of size 𝑛 (sufficiently large)\nStep 1 : calculation of the (empirical) test statistic\nWhere 𝑥 ̅ is the empirical mean, 𝑠_𝑥 is the empirical standard deviation, and 𝑚_0 is the reference average.\nObservations / realizations of a “theoretical” sample\nThe quality manager of a factory confirms that during the year 2019, the average daily number of defective parts is equal to 4.\nThe quality manager has asked (at the beginning of 2020) a team of specialized technicians to intervene in order to make some adjustments to the parameters of the production machines.\nThe quality manager is now wondering whether the current situation has changed after the intervention of the team of technicians. To do this, the quality manager chose (randomly) 50 days after the intervention and took the number of defective parts. This study gave a mean of 3.82 and a standard deviation of 1.80765.\nCan we say, with a 25% risk, that the average daily number of defective parts of defective parts has decreased?\nCan we say, with a 5% risk, that the average daily number of defective parts has decreased?\nModeling framework:\nPopulation : the days (of activity of the plant) after the intervention of the technicians\nStudied variable : the number of defective parts\nModeling assumption : the variable studied, noted 𝑋, follows a probability distribution “𝔏”\nUnknown parameter(s) : 𝑚=𝔼(𝑋) and 𝜎= 𝜎(𝑋)\nReference information : a reference average 𝑚_0=4\nTest formulation:\n[…]\nThe quality manager of a factory confirms that during the year 2019, the rate of defective parts produced by machine M is equal to 2%.\nThe quality manager asked (at the beginning of 2020) a team of specialized technicians to intervene in order to make some adjustments to the parameters of the M machine.\nThe quality manager is now wondering if, following the intervention of the team of technicians, the current situation :\nHas evolved / changed became worse (i.e., the intervention was not beneficial) Has improved (i.e., the intervention was beneficial)\nTo answer the quality manager’s questions, simply compare the current rate of defective parts with 2%.\nThe population : The parts produced by the M machine (post intervention) The studied variable : 𝑋 (Ω)= {1 (𝑑𝑒𝑓𝑒𝑐𝑡𝑖𝑣𝑒) ; 0 (𝑛𝑜𝑡 𝑑𝑒𝑓𝑒𝑐𝑡𝑖𝑣𝑒)} Modeling assumption : The studied variable, noted X, follows a Bernoulli distribution of parameter\n𝑝 = ℙ(𝑋 = 1) Unknown parameter(s) : 𝑝 Reference information : a reference proportion 𝑝_0=2%\nThe quality manager’s questions can be translated as follows:\nThe current situation has changed  𝒑≠𝒑𝟎=𝟐% The current situation has become worse  𝐩&gt;𝒑𝟎=𝟐% The current situation has improved  𝐩&lt;𝒑_𝟎=𝟐%\n\n08/exercices\nA tire manufacturer claims that the average life of a new type of tire, rated NP, is 75,000 km under certain conditions. The new quality manager at the manufacturer’s plant wanted to check this information. To do this, he randomly selected 50 NP tires and studied their lifetimes under the same conditions mentioned by the manufacturer. This study gave an average life equal to 80,000 km and a standard deviation equal to 2,500 km.\nQuestion 1 :\nCan we confirm, with a 5% risk, that the manufacturer is wrong?\nQuestion 2 :\nCan we confirm, with a 1% risk, that the manufacturer is wrong?\nModeling framework:\n\nPopulation : NP tires\nStudied variable : the lifetime\nModeling assumption : the variable studied, noted 𝑋, follows a probability distribution “𝔏”\nUnknown parameter(s) : 𝑚=𝔼(𝑋) and 𝜎= 𝜎(𝑋)\n\nEmpirical results :\nThe empirical mean (estimate of m) : 𝑥 ̅ = 80000 The empirical standard deviation (estimate of σ) : s = 2500 The size of the data set : n = 50 (&gt; 30) Reference average : 𝑚_0=75000\nWe wish to carry out a two-tailed test of the conformity of a mean with respect to a reference value / mean. The (empirical) test statistic : 𝑢_𝑜𝑏𝑠=2\nQuestion 1 :\nCan we confirm, with a 5% risk (then 1%), that the average amount of taxes is less than 1550 euros?\nQuestion 2 :\nCan we confirm, with a 5% risk, that more than half of the taxpayers pay more than 1500 euros in taxes?\nQuestion 1\nModeling framework:\nPopulation : taxpayers Studied variable : the amount of taxes (to be paid) Modeling assumption : the variable studied, noted 𝑋, follows a probability distribution “𝔏”\n\nUnknown parameter(s) : 𝑚=𝔼(𝑋) and 𝜎= 𝜎(𝑋)\n\nEmpirical results :\nThe empirical mean (estimate of m) : 𝑥 ̅ = 1510 The empirical standard deviation (estimate of σ) : s = 391.0243 The size of the data set : n = 300 (&gt; 30)\nReference information : a reference average 𝑚_0=1550\nWe wish to perform a one-tailed left-handed test of the conformity of a mean with respect to a reference value / mean.\nQuestion 1\nCalculation of the (empirical) test statistic: 𝑢_𝑜𝑏𝑠=−1.771809\nWith 𝛼=5%, we have 𝑢^∗=1.645. It implies that 𝑢_𝑜𝑏𝑠&lt;− 𝑢^∗ Therefore, we reject the null hypothesis.\nIn other words, the data allows us to confirm, with a 5% risk, that the average amount of taxes is less than 1550 euros\nWith 𝛼=1%, we have 𝑢^∗=2.33. It implies that 𝑢_𝑜𝑏𝑠&gt;− 𝑢^∗ Therefore, we do not reject the null hypothesis.\nIn other words, the data do not allow us to confirm, with a 1% risk, that the average amount of taxes is less than 1550 euros\nQuestion 2 :\nModeling framework:\nPopulation : taxpayers Studied variable : 𝑋 (Ω)= {1 (𝑡𝑎𝑥 𝑎𝑚𝑜𝑢𝑛𝑡≥1500) ; 0 (𝑡𝑎𝑥 𝑎𝑚𝑜𝑢𝑛𝑡&lt;1500)}\nModeling assumption : The studied variable, noted X, follows a Bernoulli distribution of parameter 𝑝 = ℙ(𝑋 = 1) Unknown parameter(s) : 𝑝 Reference value : 𝑝_0=0.5\nEmpirical results :\nThe size of the data set : n = 300 (&gt; 30) k (number of favorable cases) = 150 + 18 An estimate for p is given by 𝑝 ̂ = (150+18)/300 = 0.56\nWe wish to perform a one-tailed right test of the conformity of a proportion to a reference value/proportion.\nCalculation of the (empirical) test statistic: 𝑢_𝑜𝑏𝑠=2.078461\nWith 𝛼=5%, we have 𝑢^∗=1.645. It implies that 𝑢_𝑜𝑏𝑠&gt; 𝑢^∗ Therefore, we reject the null hypothesis.\nIn other words, the data allow us to confirm, with a 5% risk, that the rate of taxpayers who pay more than 1500 euros in taxes is higher than 50%.\n08/moodle\nExercise 1 :\nThe quality department of a factory claims that the percentage of defective parts is less than 3%. A data set of 150 parts taken randomly from the production line shows that there are 147 parts that meet the standards. Thus, we can deduce that :\nDefective parts represent the study population A. True B. False\nFeedback : the population is the set of items.\nThe variable studied is the number of defective parts A. True B. False\nFeedback : the studied variable follows a Bernoulli distribution whose success is the fact that the part is defective\n\n2% is the rate of defective parts A. True B. False\nFeedback : 2% is the empirical proportion of defective parts\nTo prove that the quality department is right, a one-tailed left-handed test of the conformity of a proportion to a reference value must be performed A. True B. False\nFeedback : we put in the alternative hypothesis what we want to demonstrate\nThe data allows us, with a 5% risk, to confirm that the quality department is right A. True B. False\nFeedback : After checking the calculations (using the formula for finding the test statistic associated with a test of conformity of a proportion with respect to a reference value) we see that there is no rejection of the initial hypothesis (with 5% risk) ….\n\nExercise 2\nPlant U produces cereal boxes. The plant’s quality control department determines that the average net weight of a cereal box should not be less than 200 g. In order to check for a possible malfunction, the head of the quality control department randomly took 100 boxes from the production line and measured their weight. This study gave an average weight of 203 g and a standard deviation of 15 g.\nThus, it can be deduced that:\n\nTo check if the average weight of the boxes respects the standard, we have to carry out a left one-tailed test of conformity of an average compared to a reference value A. True B. False\nFeedback : we put in the alternative hypothesis what we want to demonstrate\nThe data do not allow us, with a 5% risk, to confirm that the average weight of the boxes meets the standard. A. True B. False\nFeedback : After checking the calculations (using the formula for finding the test statistic associated with a test of conformity of a mean with respect to a reference value) we find that the initial hypothesis is rejected (with a 5% risk)….\n\nExercise 2\n\nThe data allows us, with a 1% risk, to confirm that the average weight of the boxes respects the norm. A. True B. False\nFeedback : After checking the calculations (using the formula for finding the test statistic associated with a test of conformity of a mean with respect to a reference value) we see that there is no rejection of the initial hypothesis (with a 1% risk)….",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Hypothesis Testing - Test of conformity to a reference value"
    ]
  },
  {
    "objectID": "ibs/references.html",
    "href": "ibs/references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "ibs/ch08-sets-combinatorial-analysis.html",
    "href": "ibs/ch08-sets-combinatorial-analysis.html",
    "title": "Sets and Combinatorial Analysis",
    "section": "",
    "text": "wikipedia page\nBasic set operations\nUnit 8: Counting, permutations, and combinations\nVenn Diagram",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Sets and Combinatorial Analysis"
    ]
  },
  {
    "objectID": "ibs/ch08-sets-combinatorial-analysis.html#set",
    "href": "ibs/ch08-sets-combinatorial-analysis.html#set",
    "title": "Sets and Combinatorial Analysis",
    "section": "Set",
    "text": "Set\nDefinitions : A set 𝐸 is a collection of objects, called its elements, considered without order or possible repetition. If ” 𝑥 is an element of the set 𝐸 “, then one can say that”𝑥 belongs to 𝐸 ” and we denote 𝑥 ∈ 𝐸 A set without element is called empty set: notation: ∅ A single-element set is called a singleton A two-element set, is called a pair A subset is a part of the set\nUsual sets in mathematics : ℕ” = {0, 1, 2, 3, 4, . . .} “the set of nonnegative integers ℤ” = {…, −2, −1, 0, 1, 2, …}” the set of integers ℚ={ 𝑎/𝑏, 𝑎∈ℤ, 𝑏∈ℤ, and 𝑏≠0} the set of rational numbers (the fractions) ℝ “= ]−∞, +∞[” the set of real numbers ℝ “ ”{𝑎} the set of all the real numbers in ℝ except 𝑎 ℝ^+ “= [0, +∞[” the set of positif real numbers ℝ^− ”= ]−∞, 0]” the set of negatif real numbers\nRepresentation of a set : By extension: give an exhaustive list of all its elements. By understanding: give a characteristic property of its elements. For example : 𝐴 = {𝑥 ∈ℕ ┤| x is an even number} by extension : 𝐴 = {0, 2, 4, 6, 8,…} 𝐵 = {𝑥 ∈ℤ | −2 ≤ 𝑥 ≤ 5} by extension : 𝐵 = {−2,−1, 0, 1, 2, 3, 4, 5}\nOperations on Sets : Inclusion : 𝐴 ⊂ 𝐵 : ∀ 𝑥∈𝐴 ⇒ 𝑥∈𝐵\nEquality : 𝐴 = 𝐵 ∀ 𝑥∈𝐴 ⟺𝑥∈𝐵\nNote that 𝐴 ⊆ 𝐵 implies ” 𝐴 is included in 𝐵 or equal to 𝐵 “.\nRecall that : 𝐴=𝐵 ⟺ 𝐴⊆𝐵 and 𝐵⊆𝐴.\nIntersection : 𝐴 ∩ 𝐵 ∀ 𝑥 ∈ 𝐴 ∩ 𝐵⟺𝑥 ∈ 𝐴 and 𝑥 ∈ 𝐵.\nRecall that : if 𝐴∩𝐵=∅, then one can say that 𝐴 and 𝐵 are disjoint 𝐴∩𝐵 = 𝐵∩𝐴 𝐴∩∅ = ∅ 𝐴∩(𝐵∩𝐶) = (𝐴∩𝐵)∩𝐶\nUnion : 𝐴∪𝐵 ∀ 𝑥 ∈𝐴∪𝐵⟺𝑥 ∈ 𝐴 or 𝑥 ∈ 𝐵.\nRecall that :\n𝐴⊆(𝐴∪𝐵),𝐵⊆(𝐴∪𝐵),and 𝐴∩𝐵⊆(𝐴∪𝐵) 𝐴∪𝐵=𝐵∪𝐴 𝐴∪∅=𝐴 𝐴∪(𝐵∪𝐶)=(𝐴∪𝐵)∪𝐶 𝐴∩(𝐵∪𝐶)=(𝐴∩𝐵)∪(𝐴∩𝐶)\nComplementarity : Let 𝐴, 𝐵 and 𝐶 be three sets, such that 𝐴 ⊂ 𝐵 and 𝐶⊂ 𝐵. The complement of 𝐴 in 𝐵 is the set of elements of 𝐵 not belonging to 𝐴. Notation : 𝐴 ̅ (or 𝐴^𝑐, or 𝐵∖𝐴).\nRecall that : A ∩ 𝐴 ̅ = ∅ A ∪ 𝐴 ̅ = B ((𝐴 ̅)) ̅ = A ((𝐴∩𝐶)) ̅ = 𝐴 ̅ ∪ 𝐶 ̅ and ((𝐴 ∪ 𝐶) ) ̅ = 𝐴 ̅ ∩ 𝐶 ̅\nPartition :A partition of a set 𝐸 is a set of non-empty subsets of 𝐸 (called the components of the partition) which are disjoint such that their union is equal to 𝐸.\nExample : Suppose that 𝐸={1, 2, 3, 4, 5, 6, 7}. Then : 𝐸={{1, 2, 3}, {4, 5, 6, 7}} is a partition of 𝐸 ; 𝐸={{1, 2}, {3, 4}, {5, 6, 7}} is a partition of 𝐸 ; 𝐸={{1}, {2}, {3}, {4}, {5}, {6}, {7}} is a partition of 𝐸 ; …\nSet of the parts:We call the set of the parts of 𝐴, the set of all the possible subsets of 𝐴. It is denoted 𝒫(𝐴).\nExemple : Suppose that 𝐴 = {1, 2, 3}. Then, we have: 𝒫(𝐴) = {∅, {1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}, {1, 2, 3}}\nCardinal of a set :The cardinal is the size of a set. The cardinal of a finite set is the number of elements of the set. In particular, the cardinal of the empty set is zero. Notation : |𝐸| (or #(𝐸), or Card(𝐸)) is the cardinal of the set 𝐸\nRecall that if 𝐴⊆𝐵, then |𝐴|≤|𝐵|; if 𝐴⊆𝐵, then |𝐵|=|𝐵|−|𝐴|; if 𝐴∩𝐵=∅, then |𝐴∪𝐵|=|𝐴|+|𝐵|; |𝐴∪𝐵|=|𝐴|+|𝐵|−|𝐴∩𝐵|; if |𝐴|=𝑛, then |𝒫(𝐴)|=2^𝑛.\n\nCombinatorial analysis\nThe purpose of combinatorial analysis (counting techniques) is to learn how to count the number of elements in a finite set.\nThree techniques will be addressed: Permutations Arrangements Combinations\nThese techniques depend on an operation: the factorial of a nonnegative integer.\nThe factorial :Let 𝑛 ∈ 𝑁. Its factorial is defined by :\n𝑛! = 1 × 2 × . . . × (𝑛 − 1) × 𝑛\nBy convention, we have 0! = 1. Main Property: Let 𝑘 be a nonnegative and non null integer (𝑘 ≥ 1) and let 𝑛 be a nonnegative and non null integer such that (𝑛−𝑘)≥0.\nWe have : 𝑛! = (𝑛 − 𝑘)! × (𝑛 − 𝑘 + 1) × . . . × (𝑛 − 1) × 𝑛.\nPermutations :Given a set 𝐸 of 𝑛 objects, a permutations is an ordered rearrangement, without repetition of these 𝑛 distinct objects. The number of permutations of 𝑛 objects equals 𝑛!\nArrangements : Given a set 𝐸 of 𝑛 objects (elements), we call arrangements of 𝑝 (1 ≤ 𝑝 ≤ 𝑛) objects, all ordered sequences of 𝑝 objects taken from the 𝑛 objects.\nThere are two cases:\nArrangements without repetition : When each object can only be seen once in an arrangement, the number of non-repeating arrangements of 𝑝 objects taken from 𝑛 is: 𝐴_𝑛^𝑝= 𝑛!/((𝑛−𝑝)!) where 1≤𝑝≤𝑛.\nArrangements with repetition : When an object can be observed several times in an arrangement, the number of arrangements with repetition of 𝑝 (1 ≤ 𝑝 ≤ 𝑛) objects taken from 𝑛 is equal to 𝑛^𝑝.\nRemark : The permutation of 𝑛 objects is a particular case of a non-repeating arrangement of 𝑝 objects taken from 𝑛 objects, when 𝑝 = 𝑛.\nThus, the number of permutations of 𝑛 objects equals :\n𝐴_𝑛^𝑛= 𝑛!/((𝑛−𝑛)!)=𝑛!/0!=𝑛!\nCombinations : Given a set 𝐸 of 𝑛 objects, we call combinations of 𝑝 (1 ≤ 𝑝 ≤ 𝑛) objects any set of 𝑝 objects taken  without replacement among the 𝑛 objects. In this case, the notion of order of objects is no longer taken into account. The number of combinations of 𝑝 objects taken from 𝑛 is\n𝐶_𝑛^𝑝= 𝑛!/(𝑝! × (𝑛−𝑝)!)=(𝐴_𝑛^𝑝)/𝑝!\n\n\nexemple détaillé\nHow many 10-letter words can be formed with the 26 letters of the alphabet if the letters can be reused ?\nAt each position (1 to 10) one can chose among 26 different letters. Therefore the number of possibilities will be : 26 × 26 × 26 × 26 × 26 × 26 × 26 × 26 × 26 × 26= 2610.\nHow many 10-letter words can be formed with the 26 letters of the alphabet if each letter is used only once ?\nThe number of arrangements without repetition of 10 objects taken among 26 is equal to 𝐴_26^10 = 26!/((26 − 10)!) = 26 × 25 × 24 × 23 × 22 × 21 × 20 × 19 × 18 × 17 =19 275 223 968 000 words.\nHow many different numbers of 6 digits are there\nIf there are no restrictions? If the numbers have to be divisible by 5 ? If the repetition of digits is excluded?\nThe first digit cannot be 0 otherwise the number would have 5 digits\nWithout any restriction One gets 9 × 10 ×10 ×10 ×10 × 10 = 900 000 possible numbers\nIf the number ends by 0 or 5 (divisible by 5) One gets 9 × 10 × 10 × 10 × 10 × 2 = 180 000 possible numbers\nIf a chosen digit cannot be re-used One gets 9 × 9 × 8 × 7 × 6 × 5 = 136 080 possible numbers.\n\n\nExercice\nA padlock has three wheels, each with the digits 0 to 9. How many secrets “numbers” are there?\nFrom a set of 52 cards, two cards are drawn simultaneously (without replacement). In how many different ways is this possible?\nThe code on your laptop is made up of 4 numbers (ranging from 0 to 9 each). A criminal has observed you doing the code. He managed to see only one number (but he doesn’t remember its position). What is the (maximum) number of tries for the criminal to unlock your laptop?\nThe number of possibilities is equal to 10 × 10 × 10 = 103 = 1000\nIt corresponds to the number of different ways you can choose a pair of cards from a deck of 52 cards, that is 𝐶_52^2 =1326\nFirst, the number of possible ways one can place the known digit is equal to 𝐶_4^1 =4 And then, the number of possibilities for the remaining three digits is equal to 10 × 10 × 10 = 103 = 1000. Thus the (maximum) number of tries is equal to 4 × 1000 = 4000.\n\n\nMoodle extension\n\n1\nA code has five elements: three digits and two letters If the digits of the code are distinct, then the total number of possible codes is equal to : 20 x 10 x 9 x 8 x 26 x 26 10 x 10 x 9 x 8 x 26 x 26 10 x 10 x 9 x 8 x 26 x 25 10 x 9 x 8 x 7 x 26 x 26\nFeedback: We multiply the number of possibilities to place the 2 letters (therefore the 3 digits) among 5 positions: 𝐶_5^2 (= 𝐶_5^3 )=10 , by the number of arrangements without repetition of 3 (distinct) digits 10x9x8 by the number of arrangements with repetition of 2 letters 26x26\n\n\n2\nA code has five elements: three digits and two letters If the code begins with the digit 0, then the total number of possible codes is equal to : 26 x 26 x 10 x 10 10 x 26 x 25 x 10 x 9 6 x 26 x 26 x 10 x 10 10 x 26 x 25 x 10 x 9\nFeedback: If the code starts with 0, there are 2 numbers and 2 letters left to place. We multiply the number of possibilities to place the 2 letters (therefore the 2 digits) among 4 positions: 𝐶_4^2=6 , by the number of arrangements with repetition of 2 digits 10x10 by the number of arrangements with repetition of 2 letters 26x26\n\n\n3\nA code has five elements: three digits and two letters If the code begins with the letter A, then the total number of possible codes is equal to : 26 x 10 x 10 x 10 26 x 26 x 10 x 10 4 x 26 x 10 x 10 x 10 26 x 10 x 9 x 8\nFeedback: If the code begins with A, there are 1 letter and 3 numbers left to place. We multiply the number of possibilities to place the letter (therefore the 3 digits) among 4 positions: 𝐶_41=(𝐶_43 )=4 , by the number of possible letters 26 by the number of arrangements with repetition of 3 digits 10x10x10\n\n\n4\nA code has five elements: three digits and two letters If the code begins with two letters, then the total number of possible codes is equal to : 26 x 25 x 10 x 9 x 8 26 x 25 x 10 x 10 x 10\n26 x 26 x 10 x 10 x 10\n26 x 26 x 10 x 9 x 8\nFeedback: If the code begins with 2 letters, the positions of the 2 letters and the 3 digits are imposed. We just multiply the number of arrangements with repetition of 2 letters 26x26 by the number of arrangements with repetition of 3 digits 10x10x10\n\n\n5\nA code is made up of two digits and two letters of the alphabet in all possible orders. Thus, we can deduce that if the digits of the code are distinct, then the total number of possible codes is equal to: 10 x 9 x 26 x 26 6 x 10 x 9 x 26 x 26 12 x 10 x 9 x 26 x 26 4 x 10 x 9 x 26 x 26\nFeedback: We multiply the number of possibilities to place the 2 letters (therefore the 2 digits) among 4 positions: 𝐶_4^2=6 , by the number of arrangements without repetition of 2 (distinct) digits 10x9 by the number of arrangements with repetition of 2 letters 26x26\n\n\n6\nA code is made up of two digits and two letters of the alphabet in all possible orders. Thus, we can deduce that if the code begins with the number 0, then the total number of possible codes is equal to: 10 x 26 x 26 2 x 10 x 26 x 26 3 x 10 x 26 x 26 4 x 10 x 26 x 26\nFeedback: If the code starts with 0, there are 1 digits and 2 letters left to place. We multiply the number of possibilities to place the digit (therefore the 2 letters) among 3 positions: 𝐶_3^1 (𝐶_3^2 )=3 , by the number of possible digits: 10 by the number of arrangements with repetition of 2 letters : 26x26\n\n\n7\nA code is made up of two digits and two letters of the alphabet in all possible orders. Thus, we can deduce that if the code begins with the letter A, then the total number of possible codes is equal to : 26 x 10 x 10 x 2 26 x 10 x 10 x 3 26 x 10 x 10 x 4 26 x 10 x 10 x 6\nFeedback: If the code begins with A, there are 1 letter and 2 numbers left to place. We multiply the number of possibilities to place the letter (therefore the 2 digits) among 3 positions: 𝐶_31=(𝐶_32 )=3 , by the number of possible letters 26 by the number of arrangements with repetition of 2 digits 10x10\n\n\n8\nA code is made up of two digits and two letters of the alphabet in all possible orders. Thus, we can deduce that if the code starts with two letters, then the total number of possible codes is equal to : 26 x 25 x 10 x 10\n26 x 26 x 10 x 10\n26 x 25 x 10 x 9\n26 x 26 x 10 x 9\nFeedback: If the code starts with 2 letters, the positions of the 2 letters and the 2 digits are imposed. We just multiply the number of arrangements with repetition of 2 letters 26x26 by the number of arrangements with repetition of 2 digits 10x10\n\n🏁🏁",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Sets and Combinatorial Analysis"
    ]
  },
  {
    "objectID": "ibs/ch00-preface.html",
    "href": "ibs/ch00-preface.html",
    "title": "Preface",
    "section": "",
    "text": "iPhone Weather App\n\n\n\n\nYou are probably asking yourself the question, “When and where will I use statistics?” If you read any newspaper, watch television, check weather forecast or use the Internet, you will see statistical information. There are statistics about crime, sports, education, politics, and real estate. Typically, when you read a newspaper article or watch a television news program, you are given sample information. With this information, you may make a decision about the correctness of a statement, claim, or “fact.” Statistical methods can help you make the “best educated guess.” Since you will undoubtedly be given statistical information at some point in your life, you need to know some techniques for analyzing the information thoughtfully. Think about buying a house or managing a budget. Think about your chosen profession. The fields of economics, business, psychology, education, biology, law, computer science, police science, and early childhood development require at least one course in statistics.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIncluded in this chapter are the basic ideas and words of probability and statistics. You will soon understand that statistics and probability work together. You will also learn how data are gathered and what “good” data can be distinguished from “bad.”",
    "crumbs": [
      "Teaching",
      "Preface"
    ]
  },
  {
    "objectID": "ibs/ch10-discrete-random-variable.html",
    "href": "ibs/ch10-discrete-random-variable.html",
    "title": "Discrete random variable",
    "section": "",
    "text": "After performing a random experiment, we are often interested in the function of the result obtained. For example, when we roll two balanced dice (fair dice) with two different colors, we may want to know the sum of the two numbers from the experiment. These magnitudes (or functions) of interest are values called random variables.\nA random variable \\(X\\) is a function defined from the set of possible results of a random experiment \\(\\Omega\\) and with values in \\(\\mathbb{R}\\) or a part of \\(\\mathbb{R}\\).\n\\[\\begin{align}\nX : \\Omega &\\to \\mathbb{R} \\\\\n    \\omega &\\to X(\\omega)\n\\end{align}\\]\nIt must be possible to determine the probability that it takes a given value or a given set of values. We denote by \\(X( \\Omega)\\) the set of all the values that \\(X\\) can take.\n\n\nDiscrete or continuous random variable\nDiscrete random variables can only take on a finite number of values. In another words, a random variable \\(X\\) is called discrete if \\(X(\\Omega)\\) is a finite or countable set. For example:\n\nnumber of heads appearing after ten throws of a coin,\nnumber of vehicles passing an intersection in a day,\nnumber of customers entering a store on Saturday.\n\nContinuous random variables, on the other hand, can take on any value in a given interval. For example, the mass of an animal would be a continuous random variable, as it could theoretically be any non-negative number.\nLet \\(X\\) be a discrete random variable. The law, also called distribution of \\(X\\) is the list of probabilities attributed to each of its possible values. Explicitly, for any \\(x \\in X(\\Omega)\\), we associate a value between \\(0\\) and \\(1\\) corresponding to the probability that the event \\(X = x\\) is realized and noted \\(P(X = x)\\).\nRemark: Suppose \\(X(\\Omega) = \\{x_1, x_2, ..., x_n\\}\\). Therefore:\n\\[P( X = x_1) + ... + P(X = x_n) =  \\sum_{\\substack{x \\in X(\\Omega)}} P(X = x) = 1\\]\n\n\n\nExpected value (mean) of a discrete random variable\nWe can calculate the expected value (or mean) of a discrete random variable as the weighted average of all the outcomes of that random variable based on their probabilities. We interpret expected value as the predicted average outcome if we looked at that random variable over an infinite number of trials. In mathematicals writing, we can say:\nLet \\(X\\) be a discrete random variable. Suppose that \\(X(\\Omega) = \\{x_1, x_2, ..., x_n\\}\\). We denote \\(p_i = P(X = x_i)\\), for all \\(i \\in \\{1, ..., n\\}\\).\nThe expectation of \\(X\\) is defined by:\n\\[E(X) = \\frac{x_1 \\times P(X = x_1) + ... + x_n \\times P(X = x_n)}{P(X = x_1) + ... + P(X = x_n)}\\]\n\\[E(X) = \\frac{\\sum_{i = 1}^n x_i \\times p_i}{\\sum_{i = 1}^n p_i} = \\frac{\\sum_{i = 1}^n x_i \\times p_i}{1} = \\sum_{i = 1}^n x_i \\times p_i\\]\nThe expectation \\(E(X)\\) is also called the first-order moment of \\(X\\).\n\n\n\nVariance and standard deviation\nThe variance of a discrete random variable is defined by:\n\\[V(X) = E(X^2) - (E(X))^2\\]\nStandard deviation measures the dispersion of a distribution around the expectation. In a way, the standard deviation evaluates the “average width” of the distribution, so it is expressed in the same unit as the variable. A low value of the standard deviation, implies that the distribution is homogeneous around the expectation. In other words, a smaller value of the standard deviation, implies the distribution values are close to each other and to the expectation. On the other hand, a larger value of the standard deviation, implies that the distribution is spread out: the distribution values are distant from each other and from the expectation. The standard deviation is the square root of the variance:\n\\[\\sigma(X) = \\sqrt{V(X)}\\]\n𝜎(𝑋) = √(𝕍(𝑋) )⟺𝕍(𝑋) = (𝜎(𝑋))^2\n\n\n\n\n\n\nExample\n\n\n\nExample of samples from two populations with the same mean but different variances. The red population has mean 100 and variance 100 (Standard Deviation = 10) while the blue population has mean 100 and variance 2500 (Standard Deviation = 50).\n\n\n\n\n\nSource: Wikipedia\n\n\n\n\n\nCoefficiant of variation\n\nhttps://en.wikipedia.org/wiki/Coefficient_of_variation\n\nThe coefficient of variation of a random variable is defined by\n\\[CV(X) = \\frac{\\sigma(X)}{E(X)} \\times 100\\]\nThis percentage is also an indicator of the dispersion around the expectation. By convention, we have:\n\n\\(CV(X) &lt; 15\\%\\) implies that the distribution is homogeneous around the expectation,\n\\(CV(X) \\geq 15\\%\\) implies that the distribution is heterogeneous around the expectation.\n\n\n\nCumulative Distribution Function (CDF)\nThe cumulative distribution function is a function defined on \\(\\R\\) and with values in \\([0,1]\\), denoted by \\(F_X\\). For all \\(x \\in \\R\\).\n\\[F_X(x) = P(X \\leq x) = \\sum \\limits_{j \\in X(\\Omega), \\text{ such that } j \\leq x} P(X = j)\\]\nRemarks:\n\nThe cumulative distribution function is increasing,\nThe cumulative distribution function is a step function,\nThe set of points of discontinuity is \\(X(\\Omega)\\)\n\n\n\nSpecial class of random variable\n\nBernouilli Trial Bernoulli’s test Bernoulli’s test is any test with only two possible outcomes: Success and Failure. If 𝑋 is a real random variable counting the number of successes in a Bernoulli’s test, then we have the following two cases: [𝑋 = 1] is the event which correspond to Success : with a associated probability 0 ≤ 𝑝 ≤ 1 [𝑋 = 0] is the event which correspond to Failure : with a associated probability 𝑞 = 1 − 𝑝. We say that 𝑋 follows a law of Bernoulli with parameter 𝑝 that we denote 𝑋 ∼ ℬ(𝑝). We have 𝑋(Ω)={0, 1}. Moreover, 𝔼(𝑋)=𝑝 and 𝕍(𝑋)=𝑝𝑞 where 𝑞=1−𝑝. =&gt; faire une expérience en classe pour démontrer : https://en.wikipedia.org/wiki/Bernoulli_trial\n\nThe Binomial law The random variable 𝑋= “total number of successes” after 𝑛 independent repetitions of a Bernoulli test, is called a Binomial random variable of parameters (𝑛, 𝑝) and is denoted : 𝑋∼ℬ(𝑛, 𝑝).\nBy definition, 𝑋 (Ω) = {0, 1, . . . , 𝑛}. The expression of the ℬ(𝑛, 𝑝) law is given by : 𝑝_𝑘 =ℙ(𝑋=𝑘)=𝐶_𝑛^𝑘 𝑝^𝑘 (1−𝑝)^(𝑛−𝑘), ∀ 𝑘∈𝑋(Ω), with 𝐶_𝑛^𝑘= 𝑛!/(𝑘!(𝑛−𝑘)!) By definition, 𝑋 = ∑2_(𝑖=1)^𝑛▒𝑋_𝑖 , where the 𝑋_𝑖 follow a Bernoulli ditribution with parameter 𝑝. The expectation of the Binomial distribution equals 𝔼(𝑋) = 𝑛𝑝 and its variance is equal to 𝕍(𝑋) = 𝑛𝑝𝑞, where 𝑞=1−𝑝\n\nThe Poisson law Let 𝜆&gt;0 be a fixed parameter. We say that the random variable 𝑋 with values in ℕ follows a Poisson law of parameter 𝜆 (denoted by 𝑋∼𝒫𝑜(𝜆)), if 𝑝_𝑘 =ℙ(𝑋=𝑘)=𝑒^(−𝜆) 𝜆^𝑘/𝑘!, ∀ 𝑘∈ℕ, Note that : 𝔼(𝑋) =𝕍(𝑋) = 𝜆.\nThe Poisson law can be seen as an approximation of the Binomial law when 𝑛 is “large” and 𝑝 is “small” (rare success).\n\nGeometric law The random variable 𝑋 which gives the rank of the first success (following the independent repetition of a Bernoulli’s test, having as probability of success 𝑝) is called Geometric random variable of parameter 𝑝 (denoted 𝑋 ~ 𝐺(𝑝)). By definition, 𝑋(Ω) =ℕ∖{0}. The expression of the 𝐺(𝑝) law is given by 𝑝_𝑘 =ℙ(𝑋=𝑘)=𝑝(1−𝑝)^(𝑘−1), ∀ 𝑘∈𝑋(Ω), We have : 𝔼(𝑋)=1/𝑝 𝕍(𝑋)=(1−𝑝)/𝑝^2\n𝐹_𝑋 (𝑘)=ℙ(𝑋 ≤𝑘)=1−(1−𝑝)^𝑘\nThe geometric law is often interpreted as being the lifetime or the date of death (discrete)\n\nLinear transformation Let 𝑋 be a discrete random variable. Let 𝑎 and 𝑏 be two real values. We set 𝑌 = 𝑎𝑋+𝑏. We have : 𝔼 (𝑌 ) = 𝑎 (𝔼(𝑋)) + 𝑏. 𝕍 (𝑌 ) = 𝑎^2 (𝕍(𝑋)). If 𝑎 &gt; 0, then 𝜎(𝑌 ) = 𝑎𝜎(𝑋) If 𝑎 &lt; 0, then 𝜎(𝑌 ) = (−𝑎)𝜎(𝑋)\n\nBinomial - Poisson Approximation :\nLet 𝑋 ~ ℬ(𝑛, 𝑝)\nIf 𝑛 is large enough (≥ 30) and 𝑝 is low (≤ 0.1) such that 𝑛𝑝 &lt; 15, then we can approach the Binomial law by the Poisson law of parameter 𝜆 = 𝑛𝑝, i.e.  ℙ(𝑋=𝑘)≈𝑒^(−𝜆) 𝜆^𝑘/𝑘!\n— detailed examples\nLet the binomial law : 𝑋 ~ ℬ(100, 0.09) 𝑛=100 et 𝑝=0,09 What is the value of the probability ℙ (𝑋 ≤ 5) ? What is the estimate obtained for this probability using the Poisson distribution approximation?\n\nLet the binomial law : 𝑋 ~ ℬ(100, 0.09) 𝑛=100 et 𝑝=0,09 We have: ℙ (𝑋 ≤ 5)= 0.1045 ℙ (X ≤ 5)=” ” ∑2_(𝑘=0)4▒〖𝐶_𝑛𝑘 𝑝^𝑘 (1−𝑝)^(𝑛−𝑘) 〗 = ℙ(X=0)+ ℙ(X=1) + ℙ(X=2) + ℙ(X=3) + ℙ (X=4) + ℙ (X=5) = 0,000080193512+ 0,000793122644 + 0,003882814701 + 0,012544478265 + 0,030086070125 + 0,057130471622 = 0.1045 Approximation by the poisson law (with parameter 𝜆 = 𝑛𝑝=100×0,09) that is 𝑌 ~ 𝒫𝑜(9)” hence ” ℙ(𝑋≤5)≈ℙ(𝑌≤5)= 0.1157 ℙ (Y ≤ 5)=∑2_(𝑘=0)4▒〖𝑒(−𝜆) 𝜆^𝑘/𝑘!〗 = 0,000123409804+ 0,001110688237+ 0,004998097066+ 0,014994291197+ 0,033737155192+ 0,060726879346 = 0.1157\n— Application exercices\nA game of chance involves rolling a balanced 6-sided dice. The thrower gains the double of the result obtained if it is even, otherwise, he loses the double of the result obtained. Let 𝑋 be the random variable that represents a player’s winnings.\n1  Determine the law of 𝑋 2  Calculate 𝔼(𝑋), 𝕍(𝑋) and 𝜎_𝑋 3  Plot the cumulative distribution function of 𝑋\n\n𝔼(𝑋)=∑_(𝑥∈𝑋(Ω))▒〖(𝑥 ×ℙ(𝑋 =𝑥))=1〗\n𝕍(𝑋)=∑_(𝑥∈𝑋(Ω))▒〖(𝑥^2 ×ℙ(𝑋 =𝑥))−(𝔼(𝑋))^2= 364/6〗−1^2=358/6\n𝜎_𝑋 = √(𝕍(𝑋) ) = √(358/6)=7.72442\n\nCumulative distribution function 𝐹_𝑋 : if 𝑥&lt;−10, then 𝐹_𝑋 (𝑥)=0 ; if −10≤𝑥&lt;−6, then 𝐹_𝑋 (𝑥)=ℙ(𝑋=−10)=1/6 ; if −6≤𝑥&lt;−2, then 𝐹_𝑋 (𝑥)=ℙ(𝑋=−10)+ℙ(𝑋=−6)=2/6; if −2≤𝑥&lt;4, then 𝐹_𝑋 (𝑥)=ℙ(𝑋 =−10)+ℙ(𝑋 =−6)+ℙ(𝑋 =−2)= 3/6; if 4≤𝑥&lt;8, then 𝐹_𝑋 (𝑥) =ℙ(𝑋 = −10)+ℙ(𝑋 = −6)+ℙ(𝑋 = −2)+ℙ(𝑋 = 4) =4/6; if 8≤𝑥&lt;12, then〖 𝐹〗_𝑋 (𝑥)=ℙ(𝑋=−10)+ℙ(𝑋=−6)+ℙ(𝑋= −2)+ℙ(𝑋=4)+ℙ(𝑋=8)=5/6 ; if 𝑥≥12, then〖 𝐹〗_𝑋 (𝑥)=ℙ(𝑋=−10)+ℙ(𝑋=−6)+ℙ(𝑋= −2)+ℙ(𝑋 =4)+ℙ(𝑋 =8)+ℙ(𝑋 =12)= 6/6 =1.\n\n\nexercice\nQuestion\nA transistor factory knows that due to disruption, there are currently a two out of 100 chances that a part produced will be defective. Every 2 hours, 50 parts are randomly selected (with replacement) from the transistors produced. The number of defective parts found is a random variable 𝑋. a) Determine the distribution of 𝑋. Calculate 𝐸(𝑋) and 𝑉(𝑋). b) The following quality control rule is adopted: production will be stopped if our sample contains at least 3 defective parts. What is the probability that the production will be stopped? c) What other law can be used to approach the distribution of 𝑋? Let 𝑌 be the random variable with the approximation law above. d) Calculate 𝑃 (𝑌 ≥ 3). Let 𝑍 = −2𝑌 + 5. e) Calculate 𝐸(𝑍) et 𝑉(𝑍). Let 𝑇 be the random variable that corresponds to the number of tests before getting the first defective part. f) Determine the distribution of 𝑇 g) Calculate 𝑃 (𝑇 ≤ 2). h) Calculate 𝐸(𝑇) and 𝑉(𝑇)\nRéponse\n\n𝑋 is the random variable that represents the number of defective parts among 50 parts drawn randomly. By definition, 𝑋 follows a Binomial law with parameters 𝑛 = 50 and 𝑝 = 0.02 (the probability that a part is defective). Therefore, we have :\n\n𝐸(𝑋) = 𝑛 𝑝 = 1 and 𝑉(𝑋) = 𝑛 𝑝 (1 −𝑝) = 0.98\n\nThe production will be stopped if:\n𝑃(𝑋≥3)=1−𝑃(𝑋≤2)=1−(𝑃(𝑋=0)+𝑃(𝑋=1)+𝑃(𝑋=2)) = 0.07842775\n\nTh- e conditions for approximation of the Binomial distribution by a Poisson law are satisfied, and its parameter is 𝜆 = 𝐸(𝑋) = 1,.  \n\nNow suppose that 𝑌 follows a Poisson distribution with parameter 𝜆=1. We have: 𝑃(𝑌≥3)=1−𝑃(𝑌≤2)=1−(𝑃(𝑌=0)+𝑃(𝑌=1)+𝑃(𝑌=2)) = 0.0803014 Remark : 𝑃(𝑋≥3) ≈ 𝑃 (𝑌 ≥ 3)\nLet 𝑍=−2𝑌+5. Hence, we have : 𝐸(𝑍)=−2 𝐸(𝑌)+5=3 and 𝑉(𝑍) = 4 𝑉(𝑌) = 4.\nLet us define 𝑇 as the random variable which corresponds to the number of trials before obtaining the first defective part. We notice that : 𝑇(Ω) =ℕ (the set of natural numbers). Note that 𝑊 = 𝑇 + 1 corresponds to the rank of first appearance of the defective part. By definition, 𝑊 follows a geometric law with parameter 𝑝 = 0.02 (the probability that a part is defective)\nSo, for all 𝑘 ∈ 𝑁, we have : 𝑃 (𝑇 = 𝑘) = 𝑃 (𝑊 − 1 = 𝑘) = 𝑃 (𝑊 = 𝑘 + 1) = 𝑝 〖(1 − 𝑝)〗^((𝑘 + 1) − 1) = 𝑝 〖(1 − 𝑝)〗^(𝑘 )  𝑃 (𝑇 ≤ 2)= 𝑃 (𝑊 − 1 ≤ 2)= 𝑃 (𝑊 ≤ 3)= 1 − (1 − 𝑝)^3\nand we have: 𝐸(𝑇)= 𝐸(𝑊 − 1)= 𝐸(𝑊)− 1 = 1/𝑝 − 1 = (1 − 𝑝)/𝑝 V(T) = V (W − 1) = V(W) = (1 − 𝑝)/𝑝^2\n\n\n\nmoodle\n1/ 70 people are about to pass through the airport security gate. We assume that for each person the probability that the gate does not ring is equal to 0.99. Let X be the random variable giving the number of people ringing the gate, among the 70 people. X follows the Binomial law : • ℬ(70; 0,01) • ℬ(70; 0,02) • ℬ(70; 0,03) • ℬ(70; 0,04) Feedback: n=70 repetitions of a Bernoulli test of parameter p = 1-0.99 = 0.01\n2/ 70 people are about to pass through the airport security gate. We assume that for each person the probability that the gate does not ring is equal to 0.99. Let X be the random variable giving the number of people ringing the gate, among the 70 people. The expectation 𝔼(𝑋) is : • 0,5 • 0,6 • 0,7 • 0,8 Feedback: The expectation of the binomial distribution with parameters n=70 and p=0.01 is np = 70 x 0.01 = 0.7\n3/ 70 people are about to pass through the airport security gate. We assume that for each person the probability that the gate does not ring is equal to 0.99. Let X be the random variable giving the number of people ringing the gate, among the 70 people. The variance 𝕍(𝑋) is : • 0,593 • 0,693 • 0,793 • 0,893 Feedback: The variance of the binomial law with parameters n=70 and p=0.01 is npq=np(1-p)=70x0.01x0.99\n4/ 70 people are about to pass through the airport security gate. We assume that for each person the probability that the gate does not ring is equal to 0.99. Let X be the random variable giving the number of people ringing the gate, among the 70 people. The probability that at least one person in the group rings the gate is : • 1 − 0,99 70 • 1 − 0,01 70 • 0,99 70 • 0,01 70 Feedback: The probability that no one will ring the gate is 0.99 70 . The probability of the complement (at least one person rings the gate) is therefore 1 − 0.99 70\n5/ 70 people are about to pass through the airport security gate. We assume that for each person the probability that the gate does not ring is equal to 0.99. Let X be the random variable giving the number of people ringing the gate, among the 70 people. The probability that exactly 3 people in the group will ring the gate is approximately: 0,0279 0,0379 0,0479 0,0579\nFeedback: We use for the binomial distribution the probability ℙ(𝑋=𝑘)=𝐶_𝑛^𝑘 𝑝^𝑘 (1−𝑝)^(𝑛−𝑘) with n=70, p = 0.01 and k=3\n6/ 70 people are about to pass through the airport security gate. We assume that for each person the probability that the gate does not ring is equal to 0.99. Let X be the random variable giving the number of people ringing the gate, among the 70 people. We can approximate the distribution of X, by a Poisson distribution with parameter 𝜆 equal to: 0,5 0,6 0,7 0,8\nFeedback: We check that the criteria of the approximation of the Binomial law ℬ(70; 0.01) by a Poisson law applies, and then we use 𝜆=nxp\n7/ 70 people are about to pass through the airport security gate. We assume that for each person the probability that the gate does not ring is equal to 0.99. Let X be the random variable giving the number of people ringing the gate, among the 70 people. The probability that at least two people in the group will ring the gate is approximately : 0,055 0,155 0,255 0,355\nFeedback: We use for the binomial distribution the probability ℙ(𝑋≥2)=〖1 −ℙ(𝑋&lt;2)=1−𝑃(𝑋=0)−𝑃(𝑋=1) 𝑘𝑛𝑜𝑤𝑖𝑛𝑔 𝑡ℎ𝑎𝑡 𝑃(𝑋=𝑘)= 𝐶〗_𝑛^𝑘 𝑝^𝑘 (1−𝑝)^(𝑛−𝑘)\n70 people are about to pass through the airport security gate. We assume that for each person the probability that the gate does not ring is equal to 0.99. Let X be the random variable giving the number of people ringing the gate, among the 70 people.\nThe probability that no one in the group will ring the gate is approximately : 0,2948 0,3948 0,4948 0,5948\nFeedback : The probability is 〖0,99〗^70\n\n🏁🏁",
    "crumbs": [
      "Teaching",
      "Decision Making with Statistics",
      "Discrete random variable"
    ]
  },
  {
    "objectID": "ibs/part1-data-description.html",
    "href": "ibs/part1-data-description.html",
    "title": "Data Description",
    "section": "",
    "text": "Data Description",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Data Description"
    ]
  },
  {
    "objectID": "ibs/ch01-definition-key-terms.html",
    "href": "ibs/ch01-definition-key-terms.html",
    "title": "Definitions of Statistics, Probability, and Key Terms",
    "section": "",
    "text": "Problem\n\n\n\nDetermine what the key terms refer to in the following study. We want to know the average (mean) amount of money first year college students spend at ABC College on school supplies that do not include books. We randomly surveyed 100 first year students at the college. Three of those students spent $150, $200, and $225, respectively.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe population is all first year students attending ABC College this term.\nThe sample could be all students enrolled in one section of a beginning statistics course at ABC College (although this sample may not represent the entire population).\nThe parameter is the average (mean) amount of money spent (excluding books) by first year college students at ABC College this term: the population mean.\nThe statistic is the average (mean) amount of money spent (excluding books) by first year college students in the sample.\nThe variable could be the amount of money spent (excluding books) by one first year student. Let X = the amount of money spent (excluding books) by one first year student attending ABC College.\nThe data are the dollar amounts spent by the first year students. Examples of the data are $150, $200, and $225.\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem\n\n\n\nDetermine what the key terms refer to in the following study.\nA study was conducted at a local college to analyze the average cumulative GPA’s of students who graduated last year. For each statement below find the appropriate statistical term.\n\nThe cumulative GPA of one student who graduated from the college last year.\n3.65, 2.80, 1.50, 3.90\nA group of students who graduated from the college last year, randomly selected.\nThe average cumulative GPA of students who graduated from the college last year.\nAll students who graduated from the college last year.\nthe average cumulative GPA of students in the study who graduated from the college last year.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPopulation: 5\nStatistic: 6\nParameter: 4\nSample: 3\nVariable: 1\nData: 2\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem\n\n\n\nDetermine what the key terms refer to in the following study.\nAs part of a study designed to test the safety of electric automobiles, the National Transportation Safety Board collected and reviewed data about the effects of an automobile crash on test dummies. Here is the criterion they used:\n\n\n\nSpeed at which cars crashed\nLocation of “drive” (i.e. dummies)\n\n\n\n\n35 miles/hour\nFront Seat\n\n\n\nCars with dummies in the front seats were crashed into a wall at a speed of 35 miles per hour. We want to know the proportion of dummies in the driver’s seat that would have had head injuries, if they had been actual drivers. We start with a simple random sample of 75 cars.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe population is all cars containing dummies in the front seat.\nThe sample is the 75 cars, selected by a simple random sample.\nThe parameter is the proportion of driver dummies (if they had been real people) who would have suffered head injuries in the population.\nThe statistic is proportion of driver dummies (if they had been real people) who would have suffered head injuries in the sample.\nThe variable \\(X =\\) whether a dummy (if it had been a real person) would have suffered head injuries.\nThe data are either: yes, had head injury, or no, did not.\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nflowchart TD;\n    population[Population]==&gt; |a portion (or subset) of the population|sample(Sample);\n    sample --&gt; statistic(Statistic);\n    B --&gt; D;\n    C --&gt; D;",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Definitions of Statistics, Probability, and Key Terms"
    ]
  },
  {
    "objectID": "ibs/ch01-definition-key-terms.html#exercices",
    "href": "ibs/ch01-definition-key-terms.html#exercices",
    "title": "Definitions of Statistics, Probability, and Key Terms",
    "section": "Exercices",
    "text": "Exercices\n\nExample 1\n\n\n\n\n\n\nProblem\n\n\n\nDetermine what the key terms refer to in the following study. We want to know the average (mean) amount of money first year college students spend at ABC College on school supplies that do not include books. We randomly surveyed 100 first year students at the college. Three of those students spent $150, $200, and $225, respectively.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe population is all first year students attending ABC College this term.\nThe sample could be all students enrolled in one section of a beginning statistics course at ABC College (although this sample may not represent the entire population).\nThe parameter is the average (mean) amount of money spent (excluding books) by first year college students at ABC College this term: the population mean.\nThe statistic is the average (mean) amount of money spent (excluding books) by first year college students in the sample.\nThe variable could be the amount of money spent (excluding books) by one first year student. Let X = the amount of money spent (excluding books) by one first year student attending ABC College.\nThe data are the dollar amounts spent by the first year students. Examples of the data are $150, $200, and $225.\n\n\n\n\n\n\nExample 2\n\n\n\n\n\n\nProblem\n\n\n\nDetermine what the key terms refer to in the following study.\nA study was conducted at a local college to analyze the average cumulative GPA’s of students who graduated last year. For each statement below find the appropriate statistical term.\n\nThe cumulative GPA of one student who graduated from the college last year.\n3.65, 2.80, 1.50, 3.90\nA group of students who graduated from the college last year, randomly selected.\nThe average cumulative GPA of students who graduated from the college last year.\nAll students who graduated from the college last year.\nthe average cumulative GPA of students in the study who graduated from the college last year.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPopulation: 5\nStatistic: 6\nParameter: 4\nSample: 3\nVariable: 1\nData: 2\n\n\n\n\n\n\nExample 3\n\n\n\n\n\n\nProblem\n\n\n\nDetermine what the key terms refer to in the following study.\nAs part of a study designed to test the safety of electric automobiles, the National Transportation Safety Board collected and reviewed data about the effects of an automobile crash on test dummies. Here is the criterion they used:\n\n\n\nSpeed at which cars crashed\nLocation of “drive” (i.e. dummies)\n\n\n\n\n35 miles/hour\nFront Seat\n\n\n\nCars with dummies in the front seats were crashed into a wall at a speed of 35 miles per hour. We want to know the proportion of dummies in the driver’s seat that would have had head injuries, if they had been actual drivers. We start with a simple random sample of 75 cars.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe population is all cars containing dummies in the front seat.\nThe sample is the 75 cars, selected by a simple random sample.\nThe parameter is the proportion of driver dummies (if they had been real people) who would have suffered head injuries in the population.\nThe statistic is proportion of driver dummies (if they had been real people) who would have suffered head injuries in the sample.\nThe variable \\(X =\\) whether a dummy (if it had been a real person) would have suffered head injuries.\nThe data are either: yes, had head injury, or no, did not.",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Definitions of Statistics, Probability, and Key Terms"
    ]
  },
  {
    "objectID": "ibs/ch01-definition-key-terms.html#to-recap",
    "href": "ibs/ch01-definition-key-terms.html#to-recap",
    "title": "Definitions of Statistics, Probability, and Key Terms",
    "section": "To recap",
    "text": "To recap\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nflowchart TD;\n    population[Population]==&gt; |a portion (or subset) of the population|sample(Sample);\n    sample --&gt; statistic(Statistic);\n    B --&gt; D;\n    C --&gt; D;",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Definitions of Statistics, Probability, and Key Terms"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Guillaume Gilles",
    "section": "",
    "text": "GNU GENERAL PUBLIC LICENSE\n                   Version 3, 29 June 2007\nCopyright (C) 2007 Free Software Foundation, Inc. https://fsf.org/ Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\n                        Preamble\nThe GNU General Public License is a free, copyleft license for software and other kinds of works.\nThe licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change all versions of a program–to make sure it remains free software for all its users. We, the Free Software Foundation, use the GNU General Public License for most of our software; it applies also to any other work released this way by its authors. You can apply it to your programs, too.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.\nTo protect your rights, we need to prevent others from denying you these rights or asking you to surrender the rights. Therefore, you have certain responsibilities if you distribute copies of the software, or if you modify it: responsibilities to respect the freedom of others.\nFor example, if you distribute copies of such a program, whether gratis or for a fee, you must pass on to the recipients the same freedoms that you received. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.\nDevelopers that use the GNU GPL protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License giving you legal permission to copy, distribute and/or modify it.\nFor the developers’ and authors’ protection, the GPL clearly explains that there is no warranty for this free software. For both users’ and authors’ sake, the GPL requires that modified versions be marked as changed, so that their problems will not be attributed erroneously to authors of previous versions.\nSome devices are designed to deny users access to install or run modified versions of the software inside them, although the manufacturer can do so. This is fundamentally incompatible with the aim of protecting users’ freedom to change the software. The systematic pattern of such abuse occurs in the area of products for individuals to use, which is precisely where it is most unacceptable. Therefore, we have designed this version of the GPL to prohibit the practice for those products. If such problems arise substantially in other domains, we stand ready to extend this provision to those domains in future versions of the GPL, as needed to protect the freedom of users.\nFinally, every program is threatened constantly by software patents. States should not allow patents to restrict development and use of software on general-purpose computers, but in those that do, we wish to avoid the special danger that patents applied to a free program could make it effectively proprietary. To prevent this, the GPL assures that patents cannot be used to render the program non-free.\nThe precise terms and conditions for copying, distribution and modification follow.\n                   TERMS AND CONDITIONS\n\nDefinitions.\n\n“This License” refers to version 3 of the GNU General Public License.\n“Copyright” also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.\n“The Program” refers to any copyrightable work licensed under this License. Each licensee is addressed as “you”. “Licensees” and “recipients” may be individuals or organizations.\nTo “modify” a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy. The resulting work is called a “modified version” of the earlier work or a work “based on” the earlier work.\nA “covered work” means either the unmodified Program or a work based on the Program.\nTo “propagate” a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy. Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well.\nTo “convey” a work means any kind of propagation that enables other parties to make or receive copies. Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.\nAn interactive user interface displays “Appropriate Legal Notices” to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License. If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.\n\nSource Code.\n\nThe “source code” for a work means the preferred form of the work for making modifications to it. “Object code” means any non-source form of a work.\nA “Standard Interface” means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.\nThe “System Libraries” of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form. A “Major Component”, in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.\nThe “Corresponding Source” for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work’s System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.\nThe Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.\nThe Corresponding Source for a work in source code form is that same work.\n\nBasic Permissions.\n\nAll rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.\nYou may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright. Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you.\nConveying under any other circumstances is permitted solely under the conditions stated below. Sublicensing is not allowed; section 10 makes it unnecessary.\n\nProtecting Users’ Legal Rights From Anti-Circumvention Law.\n\nNo covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures.\nWhen you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work’s users, your or third parties’ legal rights to forbid circumvention of technological measures.\n\nConveying Verbatim Copies.\n\nYou may convey verbatim copies of the Program’s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program.\nYou may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee.\n\nConveying Modified Source Versions.\n\nYou may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions:\na) The work must carry prominent notices stating that you modified\nit, and giving a relevant date.\n\nb) The work must carry prominent notices stating that it is\nreleased under this License and any conditions added under section\n7.  This requirement modifies the requirement in section 4 to\n\"keep intact all notices\".\n\nc) You must license the entire work, as a whole, under this\nLicense to anyone who comes into possession of a copy.  This\nLicense will therefore apply, along with any applicable section 7\nadditional terms, to the whole of the work, and all its parts,\nregardless of how they are packaged.  This License gives no\npermission to license the work in any other way, but it does not\ninvalidate such permission if you have separately received it.\n\nd) If the work has interactive user interfaces, each must display\nAppropriate Legal Notices; however, if the Program has interactive\ninterfaces that do not display Appropriate Legal Notices, your\nwork need not make them do so.\nA compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an “aggregate” if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation’s users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate.\n\nConveying Non-Source Forms.\n\nYou may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:\na) Convey the object code in, or embodied in, a physical product\n(including a physical distribution medium), accompanied by the\nCorresponding Source fixed on a durable physical medium\ncustomarily used for software interchange.\n\nb) Convey the object code in, or embodied in, a physical product\n(including a physical distribution medium), accompanied by a\nwritten offer, valid for at least three years and valid for as\nlong as you offer spare parts or customer support for that product\nmodel, to give anyone who possesses the object code either (1) a\ncopy of the Corresponding Source for all the software in the\nproduct that is covered by this License, on a durable physical\nmedium customarily used for software interchange, for a price no\nmore than your reasonable cost of physically performing this\nconveying of source, or (2) access to copy the\nCorresponding Source from a network server at no charge.\n\nc) Convey individual copies of the object code with a copy of the\nwritten offer to provide the Corresponding Source.  This\nalternative is allowed only occasionally and noncommercially, and\nonly if you received the object code with such an offer, in accord\nwith subsection 6b.\n\nd) Convey the object code by offering access from a designated\nplace (gratis or for a charge), and offer equivalent access to the\nCorresponding Source in the same way through the same place at no\nfurther charge.  You need not require recipients to copy the\nCorresponding Source along with the object code.  If the place to\ncopy the object code is a network server, the Corresponding Source\nmay be on a different server (operated by you or a third party)\nthat supports equivalent copying facilities, provided you maintain\nclear directions next to the object code saying where to find the\nCorresponding Source.  Regardless of what server hosts the\nCorresponding Source, you remain obligated to ensure that it is\navailable for as long as needed to satisfy these requirements.\n\ne) Convey the object code using peer-to-peer transmission, provided\nyou inform other peers where the object code and Corresponding\nSource of the work are being offered to the general public at no\ncharge under subsection 6d.\nA separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.\nA “User Product” is either (1) a “consumer product”, which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, “normally used” refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\n“Installation Information” for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.\nIf you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).\nThe requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.\nCorresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.\n\nAdditional Terms.\n\n“Additional permissions” are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.\nWhen you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it. (Additional permissions may be written to require their own removal in certain cases when you modify the work.) You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission.\nNotwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms:\na) Disclaiming warranty or limiting liability differently from the\nterms of sections 15 and 16 of this License; or\n\nb) Requiring preservation of specified reasonable legal notices or\nauthor attributions in that material or in the Appropriate Legal\nNotices displayed by works containing it; or\n\nc) Prohibiting misrepresentation of the origin of that material, or\nrequiring that modified versions of such material be marked in\nreasonable ways as different from the original version; or\n\nd) Limiting the use for publicity purposes of names of licensors or\nauthors of the material; or\n\ne) Declining to grant rights under trademark law for use of some\ntrade names, trademarks, or service marks; or\n\nf) Requiring indemnification of licensors and authors of that\nmaterial by anyone who conveys the material (or modified versions of\nit) with contractual assumptions of liability to the recipient, for\nany liability that these contractual assumptions directly impose on\nthose licensors and authors.\nAll other non-permissive additional terms are considered “further restrictions” within the meaning of section 10. If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term. If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.\nIf you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.\nAdditional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.\n\nTermination.\n\nYou may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).\nHowever, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.\nMoreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.\nTermination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.\n\nAcceptance Not Required for Having Copies.\n\nYou are not required to accept this License in order to receive or run a copy of the Program. Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance. However, nothing other than this License grants you permission to propagate or modify any covered work. These actions infringe copyright if you do not accept this License. Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so.\n\nAutomatic Licensing of Downstream Recipients.\n\nEach time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License. You are not responsible for enforcing compliance by third parties with this License.\nAn “entity transaction” is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations. If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party’s predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts.\nYou may not impose any further restrictions on the exercise of the rights granted or affirmed under this License. For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it.\n\nPatents.\n\nA “contributor” is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based. The work thus licensed is called the contributor’s “contributor version”.\nA contributor’s “essential patent claims” are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version. For purposes of this definition, “control” includes the right to grant patent sublicenses in a manner consistent with the requirements of this License.\nEach contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor’s essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version.\nIn the following three paragraphs, a “patent license” is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement). To “grant” such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party.\nIf you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients. “Knowingly relying” means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient’s use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid.\nIf, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it.\nA patent license is “discriminatory” if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License. You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007.\nNothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law.\n\nNo Surrender of Others’ Freedom.\n\nIf conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all. For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program.\n\nUse with the GNU Affero General Public License.\n\nNotwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU Affero General Public License into a single combined work, and to convey the resulting work. The terms of this License will continue to apply to the part which is the covered work, but the special requirements of the GNU Affero General Public License, section 13, concerning interaction through a network will apply to the combination as such.\n\nRevised Versions of this License.\n\nThe Free Software Foundation may publish revised and/or new versions of the GNU General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies that a certain numbered version of the GNU General Public License “or any later version” applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of the GNU General Public License, you may choose any version ever published by the Free Software Foundation.\nIf the Program specifies that a proxy can decide which future versions of the GNU General Public License can be used, that proxy’s public statement of acceptance of a version permanently authorizes you to choose that version for the Program.\nLater license versions may give you additional or different permissions. However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version.\n\nDisclaimer of Warranty.\n\nTHERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM “AS IS” WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\nLimitation of Liability.\n\nIN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\nInterpretation of Sections 15 and 16.\n\nIf the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee.\n                 END OF TERMS AND CONDITIONS\n\n        How to Apply These Terms to Your New Programs\nIf you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively state the exclusion of warranty; and each file should have at least the “copyright” line and a pointer to where the full notice is found.\n&lt;one line to give the program's name and a brief idea of what it does.&gt;\nCopyright (C) &lt;year&gt;  &lt;name of author&gt;\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.\nAlso add information on how to contact you by electronic and paper mail.\nIf the program does terminal interaction, make it output a short notice like this when it starts in an interactive mode:\n&lt;program&gt;  Copyright (C) &lt;year&gt;  &lt;name of author&gt;\nThis program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\nThis is free software, and you are welcome to redistribute it\nunder certain conditions; type `show c' for details.\nThe hypothetical commands show w' andshow c’ should show the appropriate parts of the General Public License. Of course, your program’s commands might be different; for a GUI interface, you would use an “about box”.\nYou should also get your employer (if you work as a programmer) or school, if any, to sign a “copyright disclaimer” for the program, if necessary. For more information on this, and how to apply and follow the GNU GPL, see https://www.gnu.org/licenses/.\nThe GNU General Public License does not permit incorporating your program into proprietary programs. If your program is a subroutine library, you may consider it more useful to permit linking proprietary applications with the library. If this is what you want to do, use the GNU Lesser General Public License instead of this License. But first, please read https://www.gnu.org/licenses/why-not-lgpl.html."
  },
  {
    "objectID": "digital-garden/fundamental-paper-ai/index.html",
    "href": "digital-garden/fundamental-paper-ai/index.html",
    "title": "Fundamental Papers in Artificial Intelligence",
    "section": "",
    "text": "Perceptron\nCNN Le Cun\nAttention is all you need\n\n\nReferences"
  },
  {
    "objectID": "digital-garden/hello-world/index.html",
    "href": "digital-garden/hello-world/index.html",
    "title": "print(‘Hello World!’)",
    "section": "",
    "text": "TL;DR\n\n\n\nThis essay\nHi everyone!\nI’ve been thinking to create a website, and more pricesly a blog, for a while now. I’ve never crossed the line of hypothesis until now, by fear of being judged. Expressing one’s thoughts on the web is intimidating and daunting. But I supposed the desire to have a place of my own to talk about thing that resonnate to me and pet projects I am working on is a stronger driving force than lack of self confidence.\nAs an aspirying machine learning engineer, blog posts are great opportunities to showcase your work. According to Chip Huyen, it is a great place to demonstrate “examples that convinced me of a candidate’s expertise in certain technology […] a blog post that covers in-depth detail about X that made our team go: Whoa, they really know about X.” (Huyen 2023)\nFor David Robinson, a blog is the best advice for someone wanted to start a data science career. (Robinson 2017) It helps to:\nThese days, one of the consequences of social media is a curated posts proliferation of well-curated posts and accomplishments. More and more people misunderstand what it takes to get thing done and the work behind the scenes. We end up with mostly posts announcements of finished work.\nOn the opposite of this philosophy, Andy Mutaschak loves to “work with the garage door up”. What does it mean in the digital area: publishing ongoing projects or posts that are written for oneself and not an audience. In his words. it looks like “giving a lecture about the problems you’re pondering in the shower; it’s thinking out loud about how your project doesn’t work at all. I want to see the process. I want to see you trim the artichoke.” (Matuschak n.d.)"
  },
  {
    "objectID": "digital-garden/hello-world/index.html#references",
    "href": "digital-garden/hello-world/index.html#references",
    "title": "print(‘Hello World!’)",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "digital-garden/hello-world/index.html#chip-huyen-look-for-in-resume",
    "href": "digital-garden/hello-world/index.html#chip-huyen-look-for-in-resume",
    "title": "print(‘Hello World!’)",
    "section": "[[chip-huyen-look-for-in-resume]]",
    "text": "[[chip-huyen-look-for-in-resume]]\nAs an aspirying machine learning engineer, blog posts are great opportunities to showcase your work. According to Chip Huyen, it is a great place to demonstrate “examples that convinced me of a candidate’s expertise in certain technology […] a blog post that covers in-depth detail about X that made our team go: Whoa, they really know about X.”"
  },
  {
    "objectID": "digital-garden/hello-world/index.html#advice-to-aspiring-data-scientists",
    "href": "digital-garden/hello-world/index.html#advice-to-aspiring-data-scientists",
    "title": "print(‘Hello World!’)",
    "section": "[[advice-to-aspiring-data-scientists]]",
    "text": "[[advice-to-aspiring-data-scientists]]\nFor David Robinson, a blog is the best advice for someone wanted to start a data science career. It helps to:\n\nPractice analyzing data and communicating about it: it can be easily resumed to “practice makes perfect” or in French: “C’est en forgeant qu’on devient forgeron”.\nCreate a portfolio of your work and skills: after spending hours and nights practicing your data science craft, a blog is a valuable medium to share your work. This piece of advice works well for established data scientists as well.\nGet feedback and evaluation: creating a community and interacting with an audience helps individuals to reach for better."
  },
  {
    "objectID": "digital-garden/hello-world/index.html#garage-door-open",
    "href": "digital-garden/hello-world/index.html#garage-door-open",
    "title": "print(‘Hello World!’)",
    "section": "[[garage-door-open]]",
    "text": "[[garage-door-open]]\nThese days, one of the consequences of [[social media]] is a curated posts proliferation of well-curated posts and accomplishments. More and more people misunderstand what it takes to [[get thing done]] and the work behind the scenes. We end up with mostly posts announcements of finished work.\nOn the opposite of this philosophy, Andy Mutaschak loves to “work with the garage door up”. What does it mean in the digital area: publishing ongoing projects or posts that are written for oneself and not an audience. In his words. it looks like “giving a lecture about the problems you’re pondering in the shower; it’s thinking out loud about how your project doesn’t work at all. I want to see the process. I want to see you trim the artichoke.”"
  },
  {
    "objectID": "digital-garden/hello-world/index.html#references-1",
    "href": "digital-garden/hello-world/index.html#references-1",
    "title": "print(‘Hello World!’)",
    "section": "References",
    "text": "References\n\n\nHi everyone!\nI’ve been thinking to create a website, and more pricesly a blog, for a while now. I’ve never crossed the line of hypothesis until now, by fear of being judged. Expressing one’s thoughts on the web is intimidating and daunting. But I supposed the desire to have a place of my own to talk about thing that resonnate to me and pet projects I am working on is a stronger driving force than lack of self confidence."
  },
  {
    "objectID": "digital-garden/hello-world/index.html#changelog",
    "href": "digital-garden/hello-world/index.html#changelog",
    "title": "print(‘Hello World!’)",
    "section": "Changelog",
    "text": "Changelog"
  },
  {
    "objectID": "digital-garden/hello-world/index.html#references-2",
    "href": "digital-garden/hello-world/index.html#references-2",
    "title": "print(‘Hello World!’)",
    "section": "References",
    "text": "References\n\n\n(Huyen 2023)\n(Robinson 2017)\n(Matuschak n.d.)\n\n\nHuyen, Chip. 2023. “What We Look for in a Resume.” Chip Huyen. https://huyenchip.com/2023/01/24/what-we-look-for-in-a-candidate.html.\n\nRobinson, David. 2017. “Advice to Aspiring Data Scientists: Start a Blog.” Variance Explained. http://varianceexplained.org/r/start-blog/.\n\nMatuschak, Andy. n.d. “Work with the Garage Door Up.” Andy’s Working Notes. https://notes.andymatuschak.org/About_these_notes?stackedNotes=zCMhncA1iSE74MKKYQS5PBZ. Accessed February 15, 2024.\n\nHuyen, Chip. 2023. “What We Look for in a Resume.” Chip Huyen. https://huyenchip.com/2023/01/24/what-we-look-for-in-a-candidate.html.\n\n\nMatuschak, Andy. n.d. “Work with the Garage Door Up.” Andy’s Working Notes. https://notes.andymatuschak.org/About_these_notes?stackedNotes=zCMhncA1iSE74MKKYQS5PBZ. Accessed February 15, 2024.\n\n\nRobinson, David. 2017. “Advice to Aspiring Data Scientists: Start a Blog.” Variance Explained. http://varianceexplained.org/r/start-blog/.\n\n\nwhy a website : 4ème point de la technique de feynman : transmettre [[feynman-technique]]\n[[digital-garden]]\n[[digital-garden.goals]]\n[[digital-garden-7-lessons]]\n\nlearning by doing @ 5 minutes\n\nDifference between [[zettelkasten]], [[digital-garden]]. and [[second-brain]] ?\nwhat to find on my website:\n\nblog posts documente my pet projects dendron kaggle shocase what i learned, lifelong leanre\nlecture\nstuff i read\nphoto ?"
  },
  {
    "objectID": "ibs/ch01-definition-key-terms.html#probability",
    "href": "ibs/ch01-definition-key-terms.html#probability",
    "title": "Definitions of Statistics, Probability, and Key Terms",
    "section": "Probability",
    "text": "Probability",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Definitions of Statistics, Probability, and Key Terms"
    ]
  },
  {
    "objectID": "ibs/ch01-definition-key-terms.html#key-terms",
    "href": "ibs/ch01-definition-key-terms.html#key-terms",
    "title": "Definitions of Statistics, Probability, and Key Terms",
    "section": "Key Terms",
    "text": "Key Terms",
    "crumbs": [
      "Teaching",
      "Data Description",
      "Definitions of Statistics, Probability, and Key Terms"
    ]
  },
  {
    "objectID": "digital-garden/markdown-dialect-jungle/index.html",
    "href": "digital-garden/markdown-dialect-jungle/index.html",
    "title": "The Jungle of Markdown Dialect",
    "section": "",
    "text": "TL;DR"
  },
  {
    "objectID": "digital-garden/markdown-dialect-jungle/index.html#references",
    "href": "digital-garden/markdown-dialect-jungle/index.html#references",
    "title": "The Jungle of Markdown Dialect",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "digital-garden/markdown-dialect-jungle/index.html#changelog",
    "href": "digital-garden/markdown-dialect-jungle/index.html#changelog",
    "title": "The Jungle of Markdown Dialect",
    "section": "Changelog",
    "text": "Changelog\n\n\n\n\n\n\nNote"
  },
  {
    "objectID": "digital-garden/hello-world/index.html#dont-keep-things-for-yourslef",
    "href": "digital-garden/hello-world/index.html#dont-keep-things-for-yourslef",
    "title": "print(‘Hello World!’)",
    "section": "Don’t keep things for yourslef",
    "text": "Don’t keep things for yourslef\nTransmit: The logical goal of this process is understanding a subject. The last The stage is the transmission of these new skills to an audience. This the last step is the best test to determine. People’s feedback allow us to check if we are capable of broadcasting a subject simply. (Rosie 2021)\n\nRosie. 2021. “The Feynman Learning Technique.” Farnam Street. https://fs.blog/feynman-learning-technique/."
  },
  {
    "objectID": "digital-garden/hello-world/index.html#is-it-blog-a-digital-garden",
    "href": "digital-garden/hello-world/index.html#is-it-blog-a-digital-garden",
    "title": "print(‘Hello World!’)",
    "section": "Is it blog, a Digital garden",
    "text": "Is it blog, a Digital garden\n\n[[digital-garden]]\n[[digital-garden.goals]]\n[[digital-garden-7-lessons]]"
  },
  {
    "objectID": "digital-garden/hello-world/index.html#indieweb-posse",
    "href": "digital-garden/hello-world/index.html#indieweb-posse",
    "title": "print(‘Hello World!’)",
    "section": "indieweb + posse",
    "text": "indieweb + posse"
  },
  {
    "objectID": "digital-garden/hello-world/index.html#learning-by-doing",
    "href": "digital-garden/hello-world/index.html#learning-by-doing",
    "title": "print(‘Hello World!’)",
    "section": "Learning by doing",
    "text": "Learning by doing\nlearning by doing @ 5 minutes"
  },
  {
    "objectID": "index.html#what-can-you-find-on-this-website",
    "href": "index.html#what-can-you-find-on-this-website",
    "title": "Hello, welcome on my website!",
    "section": "What can you find on this website",
    "text": "What can you find on this website\n\nblog posts documente my pet projects dendron kaggle shocase what i learned, lifelong leanre\nlecture\nstuff i read\nphoto ?"
  }
]